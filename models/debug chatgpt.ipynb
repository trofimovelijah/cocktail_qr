{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт и определение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отключение параллелизма\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ставим разные пакеты оттуда\n",
    "!pip install langchain langchain-openai langchain-community openai tiktoken langchain-huggingface -q\n",
    "!pip install beautifulsoup4 pypdf sentence-transformers faiss-cpu unstructured pypandoc -q\n",
    "#huggingface_hub  langchain_experimental langchainhub\n",
    "#!pip install unstructured \"unstructured[pdf]\" -q\n",
    "!pip install sentence-transformers numpy transformers requests -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "/home/elijah/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# импортируем библиотеки\n",
    "from langchain.document_loaders import WebBaseLoader, PyPDFLoader, UnstructuredEPubLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "#from langchain.tools.retriever import create_retriever_tool\n",
    "#from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.prompts import PromptTemplate\n",
    "import tqdm as notebook_tqdm\n",
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для использования ключа из LLM_bot\n",
    "!wget https://raw.githubusercontent.com/a-milenkin/LLM_practical_course/main/notebooks/utils.py -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Готовим коктейль с помощью RAG\n",
    "## Чутка `embeddings` с `HuggingFace` для оснастки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53102/634300143.py:13: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  hf_embeddings_model = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "# Чтение токена из файла\n",
    "def read_token(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"HUGGINGFACEHUB_API_TOKEN\"):\n",
    "                return line.split('=')[1].strip()\n",
    "    raise ValueError(\"Token not found in the specified file.\")\n",
    "\n",
    "# Загрузка токена\n",
    "token = read_token('../utils.key')\n",
    "\n",
    "# Формирование эмбеддингов\n",
    "hf_embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",  \n",
    "    #\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\", \n",
    "    #\"cointegrated/LaBSE-en-ru\",\n",
    "    model_kwargs={\n",
    "        \"device\": \"cpu\",\n",
    "        \"token\": token\n",
    "                  } \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Можно пропустить (если используете наполненную чашу векторного хранилища)\n",
    "### Немного `Document Loader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages count: 1\n",
      "max chars on page: 107261\n"
     ]
    }
   ],
   "source": [
    "# Загрузка EPUB файла от бармена-литературоведа\n",
    "loader = UnstructuredEPubLoader('../docs/Federle.epub', show_progress=True)\n",
    "doc_epub = loader.load()\n",
    "\n",
    "# смотрим, скока получилось загрузить\n",
    "print('pages count:', len(doc_epub))\n",
    "print('max chars on page:', max([len(page.page_content) for page in doc_epub]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages count: 481\n",
      "max chars on page: 1854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n#!pip install unstructured \"unstructured[pdf]\" -q\\nfrom langchain_community.document_loaders import DirectoryLoader\\nloader = DirectoryLoader(\"../docs\", glob=\"**/*.pdf\", show_progress=True)\\ndata = loader.load()'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем книгу от крутого бармена\n",
    "#loader = WebBaseLoader(url)\n",
    "loader = PyPDFLoader('../docs/Bortnik_1000.pdf')\n",
    "data = loader.load()\n",
    "\n",
    "print('pages count:', len(data))\n",
    "print('max chars on page:', max([len(page.page_content) for page in data]))\n",
    "\n",
    "# на тот случай, если решим загружать подобную литературу пачкой pdf\n",
    "\"\"\"\n",
    "#!pip install unstructured \"unstructured[pdf]\" -q\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader(\"../docs\", glob=\"**/*.pdf\", show_progress=True)\n",
    "data = loader.load()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исполним `Text splitters` и разобьём на чанки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "807"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# для gpt-3.5-turbo\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n\\n', '\\n', ' ', ''],  # Разделители для сохранения структуры\n",
    "    chunk_size=1000,  # 1000 символов (~200-250 токенов)\n",
    "    chunk_overlap=200  # 200 символов перекрытия\n",
    ")\n",
    "\n",
    "# для gpt-4o-mini\n",
    "\"\"\"splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n\\n', '\\n', ' ', ''],\n",
    "    chunk_size=2000,  # 2000 символов (~400-500 токенов)\n",
    "    chunk_overlap=300  # 300 символов перекрытия\n",
    ")\"\"\"\n",
    "\n",
    "# Разделяем книгу на части\n",
    "#documents = splitter.split_documents(doc_epub)\n",
    "\n",
    "split_documents = []\n",
    "for page in data:\n",
    "    split_documents += splitter.create_documents([page.page_content], metadatas=[page.metadata])\n",
    "\n",
    "len(split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество чанков: 807\n",
      "Максимальное количество символов в чанке: 1000\n"
     ]
    }
   ],
   "source": [
    "chunks = splitter.split_documents(data)\n",
    "print('Количество чанков:', len(chunks))\n",
    "print('Максимальное количество символов в чанке:', max([len(chunk.page_content) for chunk in chunks]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наполним чашу `Vector Store`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если нужно сохранить новый документ в базу\n",
    "try:\n",
    "    db_embed = FAISS.from_documents(\n",
    "            split_documents, \n",
    "            hf_embeddings_model\n",
    "        )\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Ошибка при создании базы данных FAISS: {e}\")\n",
    "\n",
    "\n",
    "# Сохраняем векторную базу локально\n",
    "db_embed.save_local(\"../data/faiss_db_pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нужно запустить (если используете готовое векторное хранилище)\n",
    "### Испьём чашу `Vector Store`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если нужно изъять из уже сохранённого документа из базы\n",
    "# Загрузка векторной базы данных из локального файла\n",
    "db_embed = FAISS.load_local(\n",
    "        \"../data/faiss_db_pdf\", \n",
    "        hf_embeddings_model,\n",
    "        allow_dangerous_deserialization = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "чавки, хорошо подходит для смешивания коктейлей, так \n",
      "как при создании много-\n",
      "компонентного напитка \n",
      "горький привкус исчезает.\n",
      "Curasao — это общее наз-\n",
      "вание для ликеров на основе \n",
      "кожуры одного из видов \n",
      "померанцев. Раньше этот \n",
      "вид растений рос преимуще-\n",
      "ственно на острове Кюра-\n",
      "сао недалеко от побережья \n",
      "Венесуэлы, откуда и произо-\n",
      "шло его название. В про-\n",
      "цессе изготовления напитка \n",
      "Лимонный ликер.  Этот \n",
      "ликер с фруктовым аро-\n",
      "матом производится из \n",
      "спелых плодов лимона.По-\n",
      "метка «Triple» или «Triple \n",
      "Sec» означает макси-\n",
      "мальное содержание спир-\n",
      "та 35 %. Как правило, \n",
      "крепость этого ликера не \n",
      "превышает 30 %.\n",
      "ПРИЛОЖЕНИЕВИНО\n",
      "364\n",
      "АБСЕНТВИСКИВОДКАДЖИНКОНЪЯКРОМ ТЕКИЛАЛИКЕР\n",
      "сухую кожуру обрабатывают коньяком \n",
      "или водкой для получения ароматической \n",
      "вытяжки, после чего добавляют пряности \n",
      "и травы. Ликер кюрасао бывает разных \n",
      "цветов: светло-желтого («Curasao Triple \n",
      "Sec»), оранжевого ( «Red Curasao» ), зеле-\n",
      "ного или синего ( «Curasao Вlue»), а также \n",
      "белого («White Curasao»). Обычный ликер \n",
      "содержит минимум 30 % спирта, сухие со-\n",
      "рта с пометкой «Sec» или «трижды сухие» \n",
      "(Triple Sec) содержат не менее 35 %. \n",
      "Кофейные ликеры  иногда называют \n",
      "«Мокка». Изготавливается из свежеоб-\n",
      "жаренных молотых кофейных зерен или \n",
      "порошкового кофе без использования \n",
      "ароматизаторов. Крепость от 25 %. \n",
      "Наиболее популярные марки: «Kahlua» — мексиканский \n",
      "кофейный ликер с травами и ванилью. «Tia Maria» — ко-\n",
      "фейный ликер со спиртом из сахарного \n",
      "тростника и «Batida de Cafe». \n",
      "Вишневые ликеры  — группа ликеров \n",
      "на основе фруктового сока содержит не \n",
      "менее 25 % спирта. Наиболее известны\n",
      "15 ìë ëèêåðà Curasao Blue;\n",
      "15 ìë ñèðîïà Cream of \n",
      "Coconut;\n",
      "ñîäîâàÿ âîäà.\n",
      "Äëÿ óêðàøåíèÿ: 1 êîêòåé-\n",
      "ëüíàÿ âèøíÿ, 1 êóñî÷åê \n",
      "àïåëüñèíîâîé öåäðû, \n",
      "1 êóñî÷åê ëèìîííîé öåäðû.\n",
      "1. Налить все  ингредиенты \n",
      "в стакан для лонгдринка.\n",
      "2. Аккуратно перемешать.\n",
      "3. Край стакана украсить \n",
      "вишенкой и цедрой цитру-\n",
      "совых на шпажке.\n",
      "4. Коктейль подать со \n",
      "свизлстиком (палочкой для \n",
      "перемешивания).\n",
      "ПРИЛОЖЕНИЕВИНО\n",
      "366\n",
      "АБСЕНТВИСКИВОДКАДЖИНКОНЪЯКРОМ ТЕКИЛАЛИКЕР\n",
      "АУРЕЛИЯ\n",
      "AURELIA    \n",
      "25 ìë ëèêåðà Batida de Coco;\n",
      "20 ìë ëèêåðà Curasao Blue;\n",
      "20 ìë ëèêåðà Grenadine.\n",
      "Äëÿ óêðàøåíèÿ: 1 êîêòåéëü-\n",
      "íàÿ âèøíÿ.\n",
      "1. Налить все  ингредиенты \n",
      "в стакан для предваритель-\n",
      "ного смешивания.\n",
      "2. Добавить лед и переме-\n",
      "шать.\n",
      "3. Процедить в коктейль-\n",
      "ный бокал.\n",
      "4. Вишенку на шпажке \n",
      "опустить в коктейль.\n",
      "БЕЛЫЙ ПАУК \n",
      "WHITE SPIDER   \n",
      "30 ìë áåëîãî ëèêåðà Creme \n",
      "de Menthe;\n",
      "30 ìë âîäêè.\n",
      "1. Налить все  ингредиенты \n",
      "в стакан тумблер.\n",
      "2. Добавить лед и переме-\n",
      "шать.\n",
      "3. Коктейль подать со \n",
      "свизлстиком (палочкой для \n",
      "перемешивания). \n",
      "БЛЮ ЧЕЙНДЖ \n",
      "BLUE CHANGE   \n",
      "40 ìë ëèêåðà Curasao Blue;\n",
      "80 ìë àíàíàñîâîãî ñîêà;\n",
      "80 ìë ñîêà ãðåéïôðóòà.\n",
      "Äëÿ óêðàøåíèÿ: ÷åòâåðòü \n",
      "êðóæêà àíàíàñà.\n",
      "1. В стакан для лонгдринка \n",
      "положить три кубика льда.\n",
      "2. Поочередно добавить \n",
      "все ингредиенты.\n",
      "3. Слегка перемешать.\n",
      "4. Кусочком ананаса укра-\n",
      "сить край стакана.\n",
      "40 ìë äæèíà;\n",
      "10 ìë ëèêåðà Cherry Brandy;\n",
      "10 ìë ëèêåðà Maraschino;\n",
      "10 ìë áåëîãî ëèêåðà \n",
      "Curasao.\n",
      "Äëÿ óêðàøåíèÿ: 1 êóñî÷åê \n",
      "àïåëüñèíîâîé öåäðû.\n",
      "1. Налить все ингредиенты \n",
      "в стакан для предваритель-\n",
      "ного смешивания.\n",
      "2. Добавить лед и переме-\n",
      "шать.\n",
      "3. Процедить в коктейль-\n",
      "ный бокал.\n",
      "4. Напиток сбрызнуть со-\n",
      "ком из кусочка апельси-\n",
      "новой цедры и положить \n",
      "цедру в коктейль.\n"
     ]
    }
   ],
   "source": [
    "query = \"curasao, яблочный ликер\"\n",
    "results = db_embed.similarity_search(query, k=5)\n",
    "for result in results:\n",
    "    print(result.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полирнём `Retriver` и инициализирует `llm` для вкуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если используете ключ из курса по LLM, запустите эту ячейку\n",
    "from utils import ChatOpenAI\n",
    "\n",
    "# Считываем API ключ из файла\n",
    "with open('../utils.key', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('OPENAI_API_KEY'):\n",
    "            course_api_key = line.split('=')[1].strip()\n",
    "            break\n",
    "\n",
    "# Инициализация языковой модели\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",         #\"gpt-4o-mini\", \n",
    "    temperature=0.2, \n",
    "    course_api_key=course_api_key\n",
    ")\n",
    "\n",
    "# объявление retriever \n",
    "retriever = db_embed.as_retriever(\n",
    "        search_type=\"mmr\",              # тип поиска похожих документов\n",
    "        search_kwargs={\n",
    "                \"k\": 5,                 # количество возвращаемых документов (Default: 4)\n",
    "                \"fetch_k\": 20\n",
    "            },     \n",
    "    )\n",
    "\n",
    "\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm, \n",
    "        retriever=retriever,\n",
    "        return_source_documents=True    # Возвращает исходные документы\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Месье системный промт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Системный промт для агента\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "        Ты — помощник для поиска рецептов коктейлей. У тебя есть доступ к базе данных с рецептами, вдохновлёнными литературными произведениями.\n",
    "        Когда пользователь вводит ингредиенты, используй инструмент \"Cocktail Recipe Finder\", чтобы найти подходящие рецепты.\n",
    "        Если рецепт не найден, предложи альтернативные варианты или уточни запрос.\n",
    "\n",
    "        ===\n",
    "        \n",
    "        Пример:\n",
    "        Пользователь: Какие коктейли можно сделать из водки и апельсинового сока?\n",
    "        Агент: Использую инструмент \"Cocktail Recipe Finder\" для поиска рецептов. Вот что найдено: [рецепт].\n",
    "\n",
    "        ===\n",
    "\n",
    "        Пример корректного ответа по введённым ингредиентам (ржаной виски, грейпфрутовый сок):\n",
    "        Коктейль \"Рожь и предубеждение\"\n",
    "        Состав:\n",
    "        - Ржаной виски (50 мл)\n",
    "        - Грейпфрутовый сок (90 мл)\n",
    "        Способ приготовления:\n",
    "        - Ингредиенты выливаем в стакан рокс поверх кубиков льда\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Миксуем рецепт коктейля `agent` 00х"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_53102/3865868748.py:11: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Создание инструмента\n",
    "agent_tools = [\n",
    "    Tool(\n",
    "        name=\"Cocktail Recipe Finder\",\n",
    "        func=retrieval_qa.run,\n",
    "        description=\"Используй этот инструмент, чтобы найти рецепты коктейлей по заданным ингредиентам. Вводи список ингредиентов, и инструмент вернёт подходящие рецепты. Пример: ['сок', 'виски'].\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# создание агента\n",
    "agent = initialize_agent(\n",
    "    tools=agent_tools, \n",
    "    llm=llm, \n",
    "    agent=\"conversational-react-description\",       #\"zero-shot-react-description\", \"plan-and-execute\"\n",
    "    verbose=True,\n",
    "    system_prompt=system_prompt                     # не забыть указать системный промт для вкуса\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задаём общие параметры, после чего коктейль готов\n",
    "## Вначале коктейль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объявление функции на ввод данных от пользователя\n",
    "def get_user_input():\n",
    "    \"\"\"\n",
    "    Запрашивает у пользователя ингредиенты для поиска рецептов.\n",
    "    \"\"\"\n",
    "    user_input = input(\"Введите ингредиенты, разделенные запятыми: \")\n",
    "    ingredients = [ingredient.strip() for ingredient in user_input.split(\",\")]\n",
    "    return ingredients\n",
    "\n",
    "\n",
    "# Обработка ответа\n",
    "def format_response(response):\n",
    "    if \"не знаю\" in response.lower() or \"не найдено\" in response.lower():\n",
    "        return \"К сожалению, я не нашёл коктейлей с этими ингредиентами. Попробуйте другие ингредиенты.\"\n",
    "    else:\n",
    "        return response\n",
    "    \n",
    "\n",
    "# Функция выбора стиля ответа\n",
    "def choose_style(styles):\n",
    "    chosen_style = input(\"Выберите номер стиля (по умолчанию 4): \") or \"4\"\n",
    "    return styles.get(chosen_style, \"по-умолчанию\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Да вот из этих ингредиентов можно замутить коктейль \"Яблочный курасао\", братаны!\n",
      "\n",
      "Ну вот, надо:\n",
      "- 30 мл яблочного ликера\n",
      "- 10 мл курасао\n",
      "\n",
      "Как его делать:\n",
      "1. В шейкер заливаем яблочный ликер и курасао.\n",
      "2. Лед добавляем и взбиваем как следует.\n",
      "3. В коктейльное стекло процеживаем.\n",
      "\n",
      "Подавать этот коктейль \"Яблочный курасао\" можно с кусочком яблока на краю стекла. Да будет праздник, братва!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Определение стилей\n",
    "    styles = {\n",
    "        \"1\": \"стиль космического ужаса и хтонического мрака Говарда Ф. Лавкрафта\",\n",
    "        \"2\": \"гопническо-быдляцкий жаргон\",\n",
    "        \"3\": \"экспериментальный стиль нарезок Уильяма Берроуза\",\n",
    "        \"4\": \"стиль барного меню\"  # Стиль по умолчанию\n",
    "    }\n",
    "    \n",
    "    while True:\n",
    "        ingredients = get_user_input()\n",
    "        if not ingredients:\n",
    "            print(\"Вы не ввели ингредиенты. Попробуйте снова.\")\n",
    "            continue\n",
    "        \n",
    "        # Преобразуем массив ингредиентов в строку\n",
    "        ingredients_str = \", \".join(ingredients)\n",
    "        \n",
    "        # Формируем текстовый запрос\n",
    "        user_prompt = (\n",
    "            \"\"\"Напиши, какие коктейли можно изготовить из представленных ниже ингредиентов. \n",
    "            Для каждого коктейля опиши подробный способ приготовления и укажи пропорции. \n",
    "            Отвечай строго на русском языке, используя чёткий и лаконичный формат. \n",
    "            Не добавляй лишнюю информацию, которая не относится к рецепту. \n",
    "            Ингредиенты: {ingredients}\"\"\".format(ingredients=ingredients_str)\n",
    "        )\n",
    "        response = retrieval_qa.invoke({\"query\": user_prompt})  \n",
    "        \n",
    "        # Получаем ответ без вывода его на экран\n",
    "        original_response = response[\"result\"]\n",
    "        # Выбор стиля\n",
    "        style = choose_style(styles)\n",
    "        prompt = PromptTemplate(input_variables=['output_text', 'style'],\n",
    "                                template='''Добро пожаловать в поиск коктейлей!\\nПерепиши этот текст в заданном стиле: {output_text}\\nСтиль: {style}.\\nРезультат:\\n''')\n",
    "        \n",
    "        # Генерация текста с использованием оригинального ответа и выбранного стиля\n",
    "        styled_prompt = prompt.format(output_text=original_response, style=style)\n",
    "        \n",
    "        # Применение выбранного стиля к оригинальному ответу\n",
    "        styled_response = llm.invoke(styled_prompt).content\n",
    "        print(styled_response)\n",
    "        break\n",
    "    \n",
    "    return styled_response\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Сохраняем результат в переменную\n",
    "    recipe = main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
