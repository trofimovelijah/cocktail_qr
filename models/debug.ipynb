{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт и определение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отключение параллелизма\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ставим разные пакеты оттуда\n",
    "!pip install langchain langchain-openai langchain-community openai tiktoken langchain-huggingface -q\n",
    "!pip install beautifulsoup4 pypdf sentence-transformers faiss-cpu unstructured pypandoc -q\n",
    "#huggingface_hub  langchain_experimental langchainhub\n",
    "#!pip install unstructured \"unstructured[pdf]\" -q\n",
    "!pip install sentence-transformers numpy transformers requests -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки\n",
    "from langchain.document_loaders import WebBaseLoader, PyPDFLoader, UnstructuredEPubLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "#from langchain.tools.retriever import create_retriever_tool\n",
    "#from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.prompts import PromptTemplate\n",
    "import tqdm as notebook_tqdm\n",
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для использования ключа из LLM_bot\n",
    "!wget https://raw.githubusercontent.com/a-milenkin/LLM_practical_course/main/notebooks/utils.py -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Готовим коктейль с помощью RAG\n",
    "## Чутка `embeddings` с `HuggingFace` для оснастки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение токена из файла\n",
    "def read_token(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"HUGGINGFACEHUB_API_TOKEN\"):\n",
    "                return line.split('=')[1].strip()\n",
    "    raise ValueError(\"Token not found in the specified file.\")\n",
    "\n",
    "# Загрузка токена\n",
    "token = read_token('../utils.key')\n",
    "\n",
    "# Формирование эмбеддингов\n",
    "hf_embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",  \n",
    "    #\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\", \n",
    "    #\"cointegrated/LaBSE-en-ru\",\n",
    "    model_kwargs={\n",
    "        \"device\": \"cpu\",\n",
    "        \"token\": token\n",
    "                  } \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Можно пропустить (если используете наполненную чашу векторного хранилища)\n",
    "### Немного `Document Loader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка EPUB файла от бармена-литературоведа\n",
    "loader = UnstructuredEPubLoader('../docs/Federle.epub', show_progress=True)\n",
    "doc_epub = loader.load()\n",
    "\n",
    "# смотрим, скока получилось загрузить\n",
    "print('pages count:', len(doc_epub))\n",
    "print('max chars on page:', max([len(page.page_content) for page in doc_epub]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем книгу от крутого бармена\n",
    "#loader = WebBaseLoader(url)\n",
    "\"\"\"loader = PyPDFLoader('../docs/Bortnik_1000.pdf')\n",
    "data = loader.load()\n",
    "\n",
    "print('pages count:', len(data))\n",
    "print('max chars on page:', max([len(page.page_content) for page in data]))\"\"\"\n",
    "\n",
    "# на тот случай, если решим загружать подобную литературу пачкой pdf\n",
    "\"\"\"\n",
    "#!pip install unstructured \"unstructured[pdf]\" -q\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader(\"../docs\", glob=\"**/*.pdf\", show_progress=True)\n",
    "data = loader.load()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исполним `Text splitters` и разобьём на чанки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для gpt-3.5-turbo\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n\\n', '\\n', ' ', ''],  # Разделители для сохранения структуры\n",
    "    chunk_size=1000,  # 1000 символов (~200-250 токенов)\n",
    "    chunk_overlap=200  # 200 символов перекрытия\n",
    ")\n",
    "\n",
    "# для gpt-4o-mini\n",
    "\"\"\"splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n\\n', '\\n', ' ', ''],\n",
    "    chunk_size=2000,  # 2000 символов (~400-500 токенов)\n",
    "    chunk_overlap=300  # 300 символов перекрытия\n",
    ")\"\"\"\n",
    "\n",
    "# Разделяем книгу на части\n",
    "#documents = splitter.split_documents(doc_epub)\n",
    "\n",
    "split_documents = []\n",
    "for page in doc_epub:\n",
    "    split_documents += splitter.create_documents([page.page_content], metadatas=[page.metadata])\n",
    "\n",
    "len(split_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = splitter.split_documents(doc_epub)\n",
    "print('Количество чанков:', len(chunks))\n",
    "print('Максимальное количество символов в чанке:', max([len(chunk.page_content) for chunk in chunks]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наполним чашу `Vector Store`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если нужно сохранить новый документ в базу\n",
    "try:\n",
    "    db_embed = FAISS.from_documents(\n",
    "            split_documents, \n",
    "            hf_embeddings_model\n",
    "        )\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Ошибка при создании базы данных FAISS: {e}\")\n",
    "\n",
    "\n",
    "# Сохраняем векторную базу локально\n",
    "db_embed.save_local(\"../data/faiss_db_epub\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нужно запустить (если используете готовое векторное хранилище)\n",
    "### Испьём чашу `Vector Store`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если нужно изъять из уже сохранённого документа из базы\n",
    "# Загрузка векторной базы данных из локального файла\n",
    "db_embed = FAISS.load_local(\n",
    "        \"../data/faiss_db_epub\", \n",
    "        hf_embeddings_model,\n",
    "        allow_dangerous_deserialization = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"query = \"грейпфрутовый сок, ржаной виски\"\n",
    "results = db_embed.similarity_search(query, k=5)\n",
    "for result in results:\n",
    "    print(result.page_content)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полирнём `Retriver` и инициализирует `llm` для вкуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если используете ключ из курса по LLM, запустите эту ячейку\n",
    "from utils import ChatOpenAI\n",
    "\n",
    "# Считываем API ключ из файла\n",
    "with open('../utils.key', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('OPENAI_API_KEY'):\n",
    "            course_api_key = line.split('=')[1].strip()\n",
    "            break\n",
    "\n",
    "# Инициализация языковой модели\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\",         #\"gpt-4o-mini\", \n",
    "    temperature=0.2, \n",
    "    course_api_key=course_api_key\n",
    ")\n",
    "\n",
    "# объявление retriever \n",
    "retriever = db_embed.as_retriever(\n",
    "        search_type=\"mmr\",              # тип поиска похожих документов\n",
    "        search_kwargs={\n",
    "                \"k\": 5,                 # количество возвращаемых документов (Default: 4)\n",
    "                \"fetch_k\": 20\n",
    "            },     \n",
    "    )\n",
    "\n",
    "\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm, \n",
    "        retriever=retriever,\n",
    "        return_source_documents=True    # Возвращает исходные документы\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Месье системный промт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Системный промт для агента\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "        Ты — помощник для поиска рецептов коктейлей. У тебя есть доступ к базе данных с рецептами, вдохновлёнными литературными произведениями.\n",
    "        Когда пользователь вводит ингредиенты, используй инструмент \"Cocktail Recipe Finder\", чтобы найти подходящие рецепты.\n",
    "        Если рецепт не найден, предложи альтернативные варианты или уточни запрос.\n",
    "\n",
    "        Пример:\n",
    "        Пользователь: Какие коктейли можно сделать из водки и апельсинового сока?\n",
    "        Агент: Использую инструмент \"Cocktail Recipe Finder\" для поиска рецептов. Вот что найдено: [рецепт].\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Миксуем рецепт коктейля `agent` 00х"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание инструмента\n",
    "agent_tools = [\n",
    "    Tool(\n",
    "        name=\"Cocktail Recipe Finder\",\n",
    "        func=retrieval_qa.run,\n",
    "        description=\"Используй этот инструмент, чтобы найти рецепты коктейлей по заданным ингредиентам. Вводи список ингредиентов, и инструмент вернёт подходящие рецепты. Пример: ['сок', 'виски'].\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# создание агента\n",
    "agent = initialize_agent(\n",
    "    tools=agent_tools, \n",
    "    llm=llm, \n",
    "    agent=\"conversational-react-description\",       #\"zero-shot-react-description\", \"plan-and-execute\"\n",
    "    verbose=True,\n",
    "    system_prompt=system_prompt                     # не забыть указать системный промт для вкуса\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задаём общие параметры, после чего коктейль готов\n",
    "## Вначале коктейль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объявление функции на ввод данных от пользователя\n",
    "def get_user_input():\n",
    "    \"\"\"\n",
    "    Запрашивает у пользователя ингредиенты для поиска рецептов.\n",
    "    \"\"\"\n",
    "    user_input = input(\"Введите ингредиенты, разделенные запятыми: \")\n",
    "    ingredients = [ingredient.strip() for ingredient in user_input.split(\",\")]\n",
    "    return ingredients\n",
    "\n",
    "\n",
    "# Обработка ответа\n",
    "def format_response(response):\n",
    "    if \"не знаю\" in response.lower() or \"не найдено\" in response.lower():\n",
    "        return \"К сожалению, я не нашёл коктейлей с этими ингредиентами. Попробуйте другие ингредиенты.\"\n",
    "    else:\n",
    "        return response\n",
    "    \n",
    "\n",
    "# Функция выбора стиля ответа\n",
    "def choose_style(styles):\n",
    "    chosen_style = input(\"Выберите номер стиля (по умолчанию 4): \") or \"4\"\n",
    "    return styles.get(chosen_style, \"по-умолчанию\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добро пожаловать в мир коктейлей, где таинственные ингредиенты сочетаются в непостижимых пропорциях, призывая древние силы из глубин космоса и хтонических миров! \n",
      "\n",
      "1. Коктейль \"Ржаной сурфер\":\n",
      "- 60 мл ржаного виски;\n",
      "- 90 мл грейпфрутового сока.\n",
      "\n",
      "Способ приготовления: смешайте эти загадочные ингредиенты в шейкере с ледяным дыханием, взболтайте и пролейте в бокал. Украсьте ломтиком грейпфрута, чтобы привлечь внимание древних богов.\n",
      "\n",
      "2. Коктейль \"Грейпфрутовый виски-сорбет\":\n",
      "- 45 мл ржаного виски;\n",
      "- 60 мл грейпфрутового сока.\n",
      "\n",
      "Способ приготовления: объедините эти таинственные ингредиенты в блендере с льдом, пока не получится однородная масса. Наполните стакан этим зельем и подайте с трубочкой, чтобы пробудить древние страхи и ужасы.\n",
      "\n",
      "Погрузитесь в мир загадочных коктейлей, который открывает двери в мир Лавкрафтовского ужаса и мрака!\n",
      "Сохраненный рецепт: Добро пожаловать в мир коктейлей, где таинственные ингредиенты сочетаются в непостижимых пропорциях, призывая древние силы из глубин космоса и хтонических миров! \n",
      "\n",
      "1. Коктейль \"Ржаной сурфер\":\n",
      "- 60 мл ржаного виски;\n",
      "- 90 мл грейпфрутового сока.\n",
      "\n",
      "Способ приготовления: смешайте эти загадочные ингредиенты в шейкере с ледяным дыханием, взболтайте и пролейте в бокал. Украсьте ломтиком грейпфрута, чтобы привлечь внимание древних богов.\n",
      "\n",
      "2. Коктейль \"Грейпфрутовый виски-сорбет\":\n",
      "- 45 мл ржаного виски;\n",
      "- 60 мл грейпфрутового сока.\n",
      "\n",
      "Способ приготовления: объедините эти таинственные ингредиенты в блендере с льдом, пока не получится однородная масса. Наполните стакан этим зельем и подайте с трубочкой, чтобы пробудить древние страхи и ужасы.\n",
      "\n",
      "Погрузитесь в мир загадочных коктейлей, который открывает двери в мир Лавкрафтовского ужаса и мрака!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Определение стилей\n",
    "    styles = {\n",
    "        \"1\": \"стиль космического ужаса и хтонического мрака Говарда Ф. Лавкрафта\",\n",
    "        \"2\": \"гопническо-быдляцкий жаргон\",\n",
    "        \"3\": \"экспериментальный стиль нарезок Уильяма Берроуза\",\n",
    "        \"4\": \"по-умолчанию\"  # Стиль по умолчанию\n",
    "    }\n",
    "    \n",
    "    while True:\n",
    "        ingredients = get_user_input()\n",
    "        if not ingredients:\n",
    "            print(\"Вы не ввели ингредиенты. Попробуйте снова.\")\n",
    "            continue\n",
    "        \n",
    "        # Преобразуем массив ингредиентов в строку\n",
    "        ingredients_str = \", \".join(ingredients)\n",
    "        \n",
    "        # Формируем текстовый запрос\n",
    "        user_prompt = (\n",
    "            \"\"\"Напиши, какие коктейли можно изготовить из представленных ниже ингредиентов. \n",
    "            Для каждого коктейля опиши подробный способ приготовления и укажи пропорции. \n",
    "            Отвечай строго на русском языке, используя чёткий и лаконичный формат. \n",
    "            Не добавляй лишнюю информацию, которая не относится к рецепту. \n",
    "            Ингредиенты: {ingredients}\"\"\".format(ingredients=ingredients_str)\n",
    "        )\n",
    "        response = retrieval_qa.invoke({\"query\": user_prompt})  \n",
    "        \n",
    "        # Получаем ответ без вывода его на экран\n",
    "        original_response = response[\"result\"]\n",
    "        # Выбор стиля\n",
    "        style = choose_style(styles)\n",
    "        prompt = PromptTemplate(input_variables=['output_text', 'style'],\n",
    "                                template='''Добро пожаловать в поиск коктейлей!\\nПерепиши этот текст в заданном стиле: {output_text}\\nСтиль: {style}.\\nРезультат:\\n''')\n",
    "        \n",
    "        # Генерация текста с использованием оригинального ответа и выбранного стиля\n",
    "        styled_prompt = prompt.format(output_text=original_response, style=style)\n",
    "        \n",
    "        # Применение выбранного стиля к оригинальному ответу\n",
    "        styled_response = llm.invoke(styled_prompt).content\n",
    "        \n",
    "        # Переформулировка заголовков\n",
    "        styled_response = styled_response.replace(\"Коктейль:\", \"Название коктейля:\") \n",
    "        styled_response = styled_response.replace(\"Ингредиенты:\", \"Состав:\") \n",
    "        styled_response = styled_response.replace(\"Приготовление:\", \"Способ приготовления:\")\n",
    "        print(styled_response)\n",
    "        break\n",
    "    \n",
    "    return styled_response\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Сохраняем результат в переменную\n",
    "    recipe = main()\n",
    "    # Теперь переменная recipe содержит рецепт коктейля\n",
    "    #print(\"Сохраненный рецепт:\", recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теперь озвучка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import uuid\n",
    "\n",
    "def get_token(auth_token, scope='SALUTE_SPEECH_PERS'):\n",
    "    \"\"\"\n",
    "      Выполняет POST-запрос к эндпоинту, который выдает токен.\n",
    "\n",
    "      Параметры:\n",
    "      - auth_token (str): токен авторизации, необходимый для запроса.\n",
    "      - область (str): область действия запроса API. По умолчанию — «SALUTE_SPEECH_PERS».\n",
    "\n",
    "      Возвращает:\n",
    "      - ответ API, где токен и срок его \"годности\".\n",
    "      \"\"\"\n",
    "    # Создадим идентификатор UUID (36 знаков)\n",
    "    rq_uid = str(uuid.uuid4())\n",
    "\n",
    "    # API URL\n",
    "    url = \"https://ngw.devices.sberbank.ru:9443/api/v2/oauth\"\n",
    "\n",
    "    # Заголовки\n",
    "    headers = {\n",
    "        'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        'RqUID': rq_uid,\n",
    "        'Authorization': f'Basic {auth_token}'\n",
    "    }\n",
    "\n",
    "    # Тело запроса\n",
    "    payload = {\n",
    "        'scope': scope\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Делаем POST запрос с отключенной SSL верификацией\n",
    "        # (можно скачать сертификаты Минцифры, тогда отключать проверку не надо)\n",
    "        response = requests.post(url, headers=headers, data=payload, verify=False)\n",
    "        return response\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Ошибка: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитанное значение: 'MTVjODUyZDMtZTU2Mi00ZWY5LWI3YzctZGY4YjUxZGMzMjhjOjllZmQ3NjZmLTVhYWQtNGYxOC1iN2I4LTQwOGMyY2IwZWI4Yg=='\n"
     ]
    }
   ],
   "source": [
    "# Считываем ключ авторизации из файла\n",
    "with open('../utils.key', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('SBER_API_KEY'):\n",
    "            SBER_API_KEY = line.split('=', 1)[1].strip(' \\n\\r')\n",
    "            if not SBER_API_KEY.endswith('=='):  # Если нет ==, добавляем их\n",
    "                SBER_API_KEY += '=='\n",
    "            break\n",
    "\n",
    "print(f\"Прочитанное значение: '{SBER_API_KEY}'\")\n",
    "#'MTVjODUyZDMtZTU2Mi00ZWY5LWI3YzctZGY4YjUxZGMzMjhjOjllZmQ3NjZmLTVhYWQtNGYxOC1iN2I4LTQwOGMyY2IwZWI4Yg=='\n",
    "\n",
    "response = get_token(SBER_API_KEY)\n",
    "if response != None:\n",
    "    salute_token = response.json()['access_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# синтез речи\n",
    "def synthesize_speech(text, token, format='wav16', voice='May_24000'):\n",
    "    url = \"https://smartspeech.sber.ru/rest/v1/text:synthesize\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\",\n",
    "        \"Content-Type\": \"application/text\"\n",
    "    }\n",
    "    params = {\n",
    "        \"format\": format,\n",
    "        \"voice\": voice\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, params=params, data=text.encode(), verify=False)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        # Сохранение синтезированного аудио в файл\n",
    "        with open('output.wav', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(\"Аудио успешно синтезировано и сохранено как 'output.wav'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elijah/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'smartspeech.sber.ru'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аудио успешно синтезировано и сохранено как 'output.wav'\n"
     ]
    }
   ],
   "source": [
    "synthesize_speech(recipe, salute_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"import requests\n",
    "import json\n",
    "\n",
    "# Считываем API ключ из файла\n",
    "with open('../utils.key', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('SBER_API_KEY'):\n",
    "            SBER_API_KEY = line.split('=')[1].strip()\n",
    "            break\n",
    "\n",
    "# Замените на ваши данные\n",
    "#API_URL = 'https://api.sbercloud.ru/salute/v1/speech/synthesize'\n",
    "API_URL = \"https://smartspeech.sber.ru/rest/v1/text:synthesizeе\"\n",
    "\n",
    "def synthesize_speech(text):\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {SBER_API_KEY}',\n",
    "        'Content-Type': 'application/json',\n",
    "        'Accept': 'audio/mpeg'  # Ожидаем получить аудиофайл в формате MP3\n",
    "    }\n",
    "    \n",
    "    data = {\n",
    "        'text': text,\n",
    "        'voice': 'May_24000',  # Вы можете выбрать другой голос, если необходимо\n",
    "        'emotion': 'neutral',\n",
    "        'speed': 1.0\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(API_URL, headers=headers, data=json.dumps(data), verify=False)\n",
    "        response.raise_for_status()  # Выбросит исключение для статусов 4xx и 5xx\n",
    "    except requests.exceptions.HTTPError as http_err:\n",
    "        print(f\"HTTP ошибка: {http_err}\")\n",
    "        print(f\"Ответ сервера: {response.text}\")\n",
    "    except Exception as err:\n",
    "        print(f\"Произошла ошибка: {err}\")\n",
    "    else:\n",
    "        with open('output.mp3', 'wb') as audio_file:\n",
    "            audio_file.write(response.content)\n",
    "        print(\"Аудиофайл успешно создан.\")\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Если не хотите платить денежков, то запустите эту ячейку\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Считываем ключ из файла\n",
    "with open('../utils.key', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('HUGGINGFACEHUB_API_TOKEN'):\n",
    "            # Извлекаем ключ, убирая лишние пробелы и символы\n",
    "            course_api_key = line.split('=')[1].strip()\n",
    "            break\n",
    "\n",
    "# Создаем объект языкового модели\n",
    "llm = HuggingFaceEndpoint(\n",
    "      #repo_id=\"IlyaGusev/saiga_llama3_8b\",\n",
    "      repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "      task=\"text-generation\",  # Вид задачи, в нашем случае - генерация текста\n",
    "      huggingfacehub_api_token = course_api_key\n",
    "    )\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
