{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт и определение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отключение параллелизма\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ставим разные пакеты оттуда\n",
    "!pip install langchain langchain-openai langchain-community openai tiktoken langchain-huggingface -q\n",
    "!pip install beautifulsoup4 pypdf sentence-transformers faiss-cpu unstructured pypandoc -q\n",
    "#huggingface_hub  langchain_experimental langchainhub\n",
    "#!pip install unstructured \"unstructured[pdf]\" -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки\n",
    "from langchain.document_loaders import WebBaseLoader, PyPDFLoader, UnstructuredEPubLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "#from langchain.tools.retriever import create_retriever_tool\n",
    "#from langchain.agents import initialize_agent, AgentType\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для использования ключа из LLM_bot\n",
    "!wget https://raw.githubusercontent.com/a-milenkin/LLM_practical_course/main/notebooks/utils.py -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Готовим коктейль с помощью RAG\n",
    "## Немного `Document Loader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages count: 1\n",
      "max chars on page: 107261\n"
     ]
    }
   ],
   "source": [
    "# Загрузка EPUB файла от бармена-литературоведа\n",
    "loader = UnstructuredEPubLoader('../docs/Federle.epub', show_progress=True)\n",
    "doc_epub = loader.load()\n",
    "\n",
    "# смотрим, скока получилось загрузить\n",
    "print('pages count:', len(doc_epub))\n",
    "print('max chars on page:', max([len(page.page_content) for page in doc_epub]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем книгу от крутого бармена\n",
    "#loader = WebBaseLoader(url)\n",
    "\"\"\"loader = PyPDFLoader('../docs/Bortnik_1000.pdf', show_progress=True)\n",
    "data = loader.load()\n",
    "\n",
    "print('pages count:', len(data))\n",
    "print('max chars on page:', max([len(page.page_content) for page in data]))\"\"\"\n",
    "\n",
    "# на тот случай, если решим загружать подобную литературу пачкой pdf\n",
    "\"\"\"\n",
    "#!pip install unstructured \"unstructured[pdf]\" -q\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader(\"../docs\", glob=\"**/*.pdf\", show_progress=True)\n",
    "data = loader.load()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Исполним `Text splitters` и разобьём на чанки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'split_documents = []\\nfor page in doc_epub:\\n    split_documents += splitter.create_documents([page.page_content], metadatas=[page.metadata])\\n\\nlen(split_documents)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# для gpt-3.5-turbo\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n\\n', '\\n', ' ', ''],  # Разделители для сохранения структуры\n",
    "    chunk_size=1000,  # 1000 символов (~200-250 токенов)\n",
    "    chunk_overlap=200  # 200 символов перекрытия\n",
    ")\n",
    "\n",
    "# для gpt-4o-mini\n",
    "\"\"\"splitter = RecursiveCharacterTextSplitter(\n",
    "    separators=['\\n\\n', '\\n', ' ', ''],\n",
    "    chunk_size=2000,  # 2000 символов (~400-500 токенов)\n",
    "    chunk_overlap=300  # 300 символов перекрытия\n",
    ")\"\"\"\n",
    "\n",
    "# Разделяем книгу на части\n",
    "#documents = splitter.split_documents(doc_epub)\n",
    "\n",
    "\"\"\"split_documents = []\n",
    "for page in doc_epub:\n",
    "    split_documents += splitter.create_documents([page.page_content], metadatas=[page.metadata])\n",
    "\n",
    "len(split_documents)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество чанков: 167\n",
      "Максимальное количество символов в чанке: 998\n"
     ]
    }
   ],
   "source": [
    "chunks = splitter.split_documents(doc_epub)\n",
    "print('Количество чанков:', len(chunks))\n",
    "print('Максимальное количество символов в чанке:', max([len(chunk.page_content) for chunk in chunks]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чутка `embeddings с HuggingFace`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ai-sage/Giga-Embeddings-instruct\n",
    "!pip install sentence-transformers -q\n",
    "!pip install numpy transformers -q\n",
    "#!pip install numpy -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.auto.modeling_auto because of the following error (look up to see its traceback):\nFailed to import transformers.generation.utils because of the following error (look up to see its traceback):\nNo module named 'numpy.char'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1817\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1818\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:53\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbeam_search\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BeamScorer, BeamSearchScorer, ConstrainedBeamSearchScorer\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcandidate_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     54\u001b[0m     AssistedCandidateGenerator,\n\u001b[1;32m     55\u001b[0m     AssistedCandidateGeneratorDifferentTokenizers,\n\u001b[1;32m     56\u001b[0m     CandidateGenerator,\n\u001b[1;32m     57\u001b[0m     EarlyExitCandidateGenerator,\n\u001b[1;32m     58\u001b[0m     PromptLookupCandidateGenerator,\n\u001b[1;32m     59\u001b[0m     _crop_past_key_values,\n\u001b[1;32m     60\u001b[0m     _prepare_attention_mask,\n\u001b[1;32m     61\u001b[0m     _prepare_token_type_ids,\n\u001b[1;32m     62\u001b[0m )\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     64\u001b[0m     NEED_SETUP_CACHE_CLASSES_MAPPING,\n\u001b[1;32m     65\u001b[0m     QUANT_BACKEND_CLASSES_MAPPING,\n\u001b[1;32m     66\u001b[0m     GenerationConfig,\n\u001b[1;32m     67\u001b[0m     GenerationMode,\n\u001b[1;32m     68\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/transformers/generation/candidate_generator.py:26\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sklearn_available():\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roc_curve\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcache_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DynamicCache\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/sklearn/__init__.py:73\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa: F401 E402\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     __check_build,\n\u001b[1;32m     71\u001b[0m     _distributor_init,\n\u001b[1;32m     72\u001b[0m )\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/sklearn/base.py:19\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/sklearn/utils/__init__.py:15\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_estimator_html_repr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m estimator_html_repr\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/sklearn/utils/_chunking.py:11\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:14\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/scipy/sparse/__init__.py:300\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m_warnings\u001b[39;00m\n\u001b[0;32m--> 300\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_csr\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/scipy/sparse/_base.py:5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (asmatrix, check_reshape_kwargs, check_shape,\n\u001b[1;32m      6\u001b[0m                        get_sum_dtype, isdense, isscalarlike,\n\u001b[1;32m      7\u001b[0m                        matrix, validateaxis, getdtype)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_matrix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/scipy/sparse/_sputils.py:10\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m np_long, np_ulong\n\u001b[1;32m     13\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupcast\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetdtype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misscalarlike\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misintlike\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misshape\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124missequence\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124misdense\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mismatrix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_sum_dtype\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbroadcast_shapes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/scipy/_lib/_util.py:13\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_namespace, is_numpy, xp_size\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docscrape\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionDoc, Parameter\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/scipy/_lib/_array_api.py:18\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m array_api_compat\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray_api_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     is_array_api_obj,\n\u001b[1;32m     20\u001b[0m     size \u001b[38;5;28;01mas\u001b[39;00m xp_size,\n\u001b[1;32m     21\u001b[0m     numpy \u001b[38;5;28;01mas\u001b[39;00m np_compat,\n\u001b[1;32m     22\u001b[0m     device \u001b[38;5;28;01mas\u001b[39;00m xp_device,\n\u001b[1;32m     23\u001b[0m     is_numpy_namespace \u001b[38;5;28;01mas\u001b[39;00m is_numpy,\n\u001b[1;32m     24\u001b[0m     is_cupy_namespace \u001b[38;5;28;01mas\u001b[39;00m is_cupy,\n\u001b[1;32m     25\u001b[0m     is_torch_namespace \u001b[38;5;28;01mas\u001b[39;00m is_torch,\n\u001b[1;32m     26\u001b[0m     is_jax_namespace \u001b[38;5;28;01mas\u001b[39;00m is_jax,\n\u001b[1;32m     27\u001b[0m     is_array_api_strict_namespace \u001b[38;5;28;01mas\u001b[39;00m is_array_api_strict\n\u001b[1;32m     28\u001b[0m )\n\u001b[1;32m     30\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_asarray\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marray_namespace\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massert_almost_equal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124massert_array_almost_equal\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mget_xp_devices\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxp_take_along_axis\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxp_unsupported_param_msg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxp_vector_norm\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     39\u001b[0m ]\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/scipy/_lib/array_api_compat/numpy/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m \u001b[38;5;66;03m# noqa: F403\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# from numpy import * doesn't overwrite these builtin names\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/numpy/__init__.py:370\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m:\n\u001b[1;32m    367\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe current Numpy installation (\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m) fails to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    368\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpass simple sanity checks. This can be caused for example \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    369\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby incorrect BLAS library being linked in, or by mixing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 370\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage managers (pip, conda, apt, ...). Search closed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    371\u001b[0m            \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy issues for similar problems.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__file__\u001b[39m)) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy.char'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1817\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1818\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/usr/lib/python3.12/importlib/__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1387\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1360\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1331\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:935\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:995\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:488\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/transformers/models/auto/modeling_auto.py:21\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto_factory\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     22\u001b[0m     _BaseAutoBackboneClass,\n\u001b[1;32m     23\u001b[0m     _BaseAutoModelClass,\n\u001b[1;32m     24\u001b[0m     _LazyAutoMapping,\n\u001b[1;32m     25\u001b[0m     auto_class_update,\n\u001b[1;32m     26\u001b[0m )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_auto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CONFIG_MAPPING_NAMES\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:40\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeneration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GenerationMixin\n\u001b[1;32m     43\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1805\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1805\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1806\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1819\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1818\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1820\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1821\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1822\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.generation.utils because of the following error (look up to see its traceback):\nNo module named 'numpy.char'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m hf_embeddings_model \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRuslanNLP/rubert-base\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\", \u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#\"cointegrated/LaBSE-en-ru\",\u001b[39;49;00m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdevice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     emit_warning()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/langchain_community/embeddings/huggingface.py:84\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     warn_deprecated(\n\u001b[1;32m     75\u001b[0m         since\u001b[38;5;241m=\u001b[39msince,\n\u001b[1;32m     76\u001b[0m         removal\u001b[38;5;241m=\u001b[39mremoval,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m constructor instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     81\u001b[0m     )\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/sentence_transformers/__init__.py:14\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     10\u001b[0m     export_dynamic_quantized_onnx_model,\n\u001b[1;32m     11\u001b[0m     export_optimized_onnx_model,\n\u001b[1;32m     12\u001b[0m     export_static_quantized_openvino_model,\n\u001b[1;32m     13\u001b[0m )\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[1;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm, trange\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, is_torch_npu_available\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BatchEncoding\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1806\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1805\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m-> 1806\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n\u001b[1;32m   1808\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1805\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[1;32m   1804\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1805\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1806\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1807\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[0;32m~/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/transformers/utils/import_utils.py:1819\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1817\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1818\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1819\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1820\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1821\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1822\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.auto.modeling_auto because of the following error (look up to see its traceback):\nFailed to import transformers.generation.utils because of the following error (look up to see its traceback):\nNo module named 'numpy.char'"
     ]
    }
   ],
   "source": [
    "hf_embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"RuslanNLP/rubert-base\",  \n",
    "    #\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\", \n",
    "    #\"cointegrated/LaBSE-en-ru\",\n",
    "    model_kwargs={\n",
    "        \"device\": \"cpu\"\n",
    "                  } \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Наполним чашу `Vector Store`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если нужно сохранить новый документ в базу\n",
    "try:\n",
    "    db_embed = FAISS.from_documents(\n",
    "            split_documents, \n",
    "            hf_embeddings_model\n",
    "        )\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Ошибка при создании базы данных FAISS: {e}\")\n",
    "\n",
    "\n",
    "# Сохраняем векторную базу локально\n",
    "db_embed.save_local(\"../data/faiss_db_epub\")\n",
    "\n",
    "# Если нужно изъять из уже сохранённого документа из базы\n",
    "# Загрузка векторной базы данных из локального файла\n",
    "db_embed = FAISS.load_local(\n",
    "        \"../data/faiss_db_epub\", \n",
    "        hf_embeddings_model,\n",
    "        allow_dangerous_deserialization = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Рожь и предубеждение\\n\\nГОРДОСТЬ И ПРЕДУБЕЖДЕНИЕ (1813)\\n\\nДЖЕЙН ОСТИН\\n\\nРоман благородных нравов XIX века подарил Джейн Остин шанс еще при жизни (хоть и недолгой – всего 41 год) вкусить свои пять минут славы. «Гордость и предубеждение» повествует о попытках семейства Беннет выдать замуж своих дочерей. От лица одной из пяти девиц и ведется рассказ. Увы, Элизабет – в одной из экранизаций блеснувшая выразительными скулами Киры Найтли – та еще язва, и ее жажда припечатать всех и каждого чуть ли не затмевает ее трепетное чувство к мистеру Дарси, джентльмену с завидным самомнением (зато ну очень богатому!). Впрочем, все кончается восхитительной двойной свадьбой. Вот и мы сосватаем две сильные натуры – терпкую пряность ржи и жизнеутверждающую горечь грейпфрута – и на славу погуляем на нашем импровизированном торжестве:\\n\\n90 мл грейпфрутового сока;\\n\\n50 мл ржаного виски.'"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultsdb = db_embed.similarity_search(\"Джейн Остин\")\n",
    "resultsdb[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полирнём `Retriver` и инициализирует `llm` для вкуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если используете ключ из курса по LLM, запустите эту ячейку\n",
    "from utils import ChatOpenAI\n",
    "\n",
    "# Считываем API ключ из файла\n",
    "with open('../utils.key', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('OPENAI_API_KEY'):\n",
    "            course_api_key = line.split('=')[1].strip()\n",
    "            break\n",
    "\n",
    "# Инициализация языковой модели\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-3.5-turbo\", #\"gpt-4o-mini\", \n",
    "    temperature=0.2, \n",
    "    course_api_key=course_api_key\n",
    ")\n",
    "\n",
    "# объявление retriever \n",
    "retriever = db_embed.as_retriever(\n",
    "        search_type=\"mmr\",          # тип поиска похожих документов\n",
    "        search_kwargs={\"k\": 5},     # количество возвращаемых документов (Default: 4)\n",
    "        core_threshold=None,        # минимальный порог для поиска \"similarity_score_threshold\"\n",
    "    )\n",
    "\n",
    "\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "        llm=llm, \n",
    "        retriever=retriever\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Предполагаем, что retriever.invoke возвращает список объектов Document\n",
    "results = retriever.invoke(\"Джейн Остин\")\n",
    "\n",
    "# Извлекаем содержимое page_content из каждого элемента списка\n",
    "formatted_contents = []\n",
    "\n",
    "for result in results:\n",
    "    # Проверяем, что результат является объектом Document и содержит page_content\n",
    "    if hasattr(result, 'page_content'):\n",
    "        page_content = result.page_content\n",
    "        # Форматируем содержимое по абзацам\n",
    "        formatted_paragraphs = \"\\n\\n\".join(paragraph.strip() for paragraph in page_content.split('\\n') if paragraph.strip())\n",
    "        formatted_contents.append(formatted_paragraphs)\n",
    "\n",
    "# Объединяем все отформатированные содержимые в один текст\n",
    "final_output = \"\\n\\n\".join(formatted_contents)\n",
    "\n",
    "# Выводим окончательный результат\n",
    "print(final_output)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Месье системный промт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '.venv (Python 3.12.3)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/home/elijah/Documents/LLM/cocktail_qr/.venv/bin/python -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Системный промт для агента\n",
    "system_prompt = (\n",
    "    \"\"\"Ты первоклассный бармен-литературовед. \n",
    "    Со всем почтением и любовью к величайшим литераторам ты содержишь целую библиотеку коктейлей (алкогольных и безалкогольных), \n",
    "    навеянных их произведениями и хранишь её в векторной базе. По запросу ты готов приготовить коктейль из своей коллекции рецептов, который не только утолит жажду, \n",
    "    но и оживит самые яркие литературные сюжеты. Выбирай ингредиенты и расскажи, какие коктейли можно приготовить, а также чем дополнить рецепты \n",
    "    для создания новых уникальных напитков.\n",
    "    Если от возлияний в голове гудит, а в животе урчит, предложи коктейли «Яйца красит Prada», «Дон Кревет» и другие «Закуски книголюба». \n",
    "    Пусти в ход наши питейные игры, после которых самое время подсчитать под столом своих истинных друзей…\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Миксуем рецепт коктейля `agent` 00х"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание инструмента\n",
    "agent_tools = [\n",
    "    Tool(\n",
    "        name=\"Cocktail Recipe Finder\",\n",
    "        func=retrieval_qa.run,\n",
    "        description=\"Находит рецепты коктейлей по заданным ингредиентам.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# создание агента\n",
    "agent = initialize_agent(\n",
    "    tools=agent_tools, \n",
    "    llm=llm, \n",
    "    agent=\"zero-shot-react-description\", \n",
    "    verbose=True,\n",
    "    system_prompt=system_prompt         # не забыть указать системный промт для вкуса\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задаём общие параметры, после чего коктейль готов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объявление функции на ввод данных от пользователя\n",
    "\n",
    "def get_user_input():\n",
    "    \"\"\"\n",
    "    Запрашивает у пользователя ингредиенты для поиска рецептов.\n",
    "    \"\"\"\n",
    "    user_input = input(\"Введите ингредиенты, разделенные запятыми: \")\n",
    "    ingredients = [ingredient.strip() for ingredient in user_input.split(\",\")]\n",
    "    return ingredients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Добро пожаловать в поиск коктейлей!\n",
      "Запрашиваю информацию...\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAction: Cocktail Recipe Finder  \n",
      "Action Input: виски, ликер  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mВиски — это ароматный напиток, производимый из дистиллята на основе различных видов зерна и выдерживаемый в дубовых бочках. Он родом из Америки, Канады, Ирландии или Шотландии. Ликер, в свою очередь, это сладкий алкогольный напиток, который обычно содержит ароматизаторы, такие как фрукты, травы или специи, и может быть использован в коктейлях или употребляться в чистом виде. Если вам нужна более конкретная информация о каком-либо из этих напитков, пожалуйста, уточните ваш вопрос.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Cocktail Recipe Finder  \n",
      "Action Input: виски, ликер  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mВиски - это ароматный напиток, производимый из дистиллята на основе различных видов зерна и выдерживаемый в дубовых бочках. Он родом из Америки, Канады, Ирландии или Шотландии. Ликер - это сладкий алкогольный напиток, который обычно содержит ароматизаторы, такие как фрукты, травы или специи, и может быть использован в коктейлях или употребляться в чистом виде. Если вам нужна дополнительная информация о конкретных видах виски или ликеров, пожалуйста, уточните.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Cocktail Recipe Finder  \n",
      "Action Input: виски, ликер  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mВиски — это ароматный напиток, производимый из дистиллята на основе различных видов зерна и выдерживаемый в дубовых бочках. Он родом из Америки, Канады, Ирландии или Шотландии. Ликер — это сладкий алкогольный напиток, который обычно содержит ароматизаторы, такие как фрукты, травы или специи, и может быть использован в коктейлях или употребляться в чистом виде. Если вам нужна дополнительная информация о каком-либо из этих напитков, пожалуйста, уточните.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Cocktail Recipe Finder  \n",
      "Action Input: виски, ликер  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mВиски — это ароматный напиток, производимый из дистиллята на основе различных видов зерна и выдерживаемый в дубовых бочках. Он родом из Америки, Канады, Ирландии или Шотландии. Ликер, в свою очередь, это сладкий алкогольный напиток, который часто содержит фрукты, травы или специи. В тексте упоминается дынный ликер, который используется в коктейле с текилой и газированной водой. Если у вас есть конкретные вопросы о виски или ликере, пожалуйста, уточните!\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Cocktail Recipe Finder  \n",
      "Action Input: виски, ликер  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mВиски — это ароматный напиток, производимый из дистиллята на основе различных видов зерна и выдерживаемый в дубовых бочках. Он родом из Америки, Канады, Ирландии или Шотландии. Ликер, в свою очередь, это сладкий алкогольный напиток, который часто содержит фрукты, травы или специи. Если вам нужна дополнительная информация о каком-либо из этих напитков, пожалуйста, уточните.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Cocktail Recipe Finder  \n",
      "Action Input: виски, ликер  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mВиски — это ароматный напиток, производимый из дистиллята на основе различных видов зерна и выдерживаемый в дубовых бочках. Он родом из Америки, Канады, Ирландии или Шотландии. Ликер, в свою очередь, это сладкий спиртной напиток, который часто содержит фрукты, травы или специи. В вашем вопросе упоминается дынный ликер, который используется в коктейле с текилой и газированной водой. Если у вас есть конкретные вопросы о виски или ликере, пожалуйста, уточните!\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Cocktail Recipe Finder  \n",
      "Action Input: виски, ликер  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mВиски — это ароматный напиток, производимый из дистиллята на основе различных видов зерна и выдерживаемый в дубовых бочках. Он родом из Америки, Канады, Ирландии или Шотландии. Ликер, в свою очередь, это сладкий алкогольный напиток, который часто содержит фрукты, травы или специи. Если вам нужна дополнительная информация о каком-то конкретном ликере, пожалуйста, уточните.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Cocktail Recipe Finder  \n",
      "Action Input: виски, ликер  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mВиски — это ароматный напиток, производимый из дистиллята на основе различных видов зерна и выдерживаемый в дубовых бочках. Он родом из Америки, Канады, Ирландии или Шотландии. Ликер, в свою очередь, это сладкий алкогольный напиток, который может содержать различные вкусовые добавки, такие как фрукты, травы или специи. Если у вас есть конкретные вопросы о виски или ликере, пожалуйста, уточните!\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Cocktail Recipe Finder  \n",
      "Action Input: виски, ликер  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mВиски — это ароматный напиток, производимый из дистиллята на основе различных видов зерна и выдерживаемый в дубовых бочках. Он может быть ржаным или бурбоном. Ликер — это сладкий алкогольный напиток, который часто содержит фрукты, травы или специи. В контексте вашего запроса, дынный ликер упоминается как один из ингредиентов в коктейле. Если у вас есть конкретный вопрос о виски или ликере, пожалуйста, уточните!\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Cocktail Recipe Finder  \n",
      "Action Input: виски, ликер  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mВиски — это ароматный напиток, производимый из дистиллята на основе различных видов зерна и выдерживаемый в дубовых бочках. Он может быть ржаным или бурбоном. Ликер — это сладкий спиртной напиток, который часто содержит фрукты, травы или специи. В контексте вашего запроса, дынный ликер упоминается как один из ингредиентов в коктейле. Если у вас есть конкретные вопросы о виски или ликере, пожалуйста, уточните!\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Cocktail Recipe Finder  \n",
      "Action Input: виски, ликер  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mВиски — это ароматный напиток, производимый из дистиллята на основе различных видов зерна и выдерживаемый в дубовых бочках. Он может быть ржаным или бурбоном. Ликер — это сладкий алкогольный напиток, который часто содержит фрукты, травы или специи. В контексте вашего запроса, дынный ликер упоминается как один из ингредиентов в коктейле. Если у вас есть конкретный вопрос о виски или ликере, пожалуйста, уточните!\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Cocktail Recipe Finder  \n",
      "Action Input: виски, ликер  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mВиски — это ароматный напиток, производимый из дистиллята на основе различных видов зерна и выдерживаемый в дубовых бочках. Он родом из Америки, Канады, Ирландии или Шотландии. Ликер, в свою очередь, это сладкий спиртной напиток, который может содержать различные ароматизаторы, такие как фрукты, травы или специи. Если вам нужна дополнительная информация о каком-то конкретном ликере, пожалуйста, уточните.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Cocktail Recipe Finder  \n",
      "Action Input: виски, ликер  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mВиски — это ароматный напиток, производимый из дистиллята на основе различных видов зерна и выдерживаемый в дубовых бочках. Он родом из Америки, Канады, Ирландии или Шотландии. Ликер, в свою очередь, это сладкий алкогольный напиток, который часто содержит фрукты, травы или специи. В вашем вопросе упоминается дынный ликер, который используется в коктейле с текилой и газированной водой. Если вам нужна дополнительная информация о каком-либо из этих напитков, пожалуйста, уточните.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Cocktail Recipe Finder  \n",
      "Action Input: виски, ликер  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mВиски — это ароматный напиток, который производится из дистиллята на основе различных видов зерна и выдерживается в дубовых бочках. Он родом из Америки, Канады, Ирландии или Шотландии. Ликер, в свою очередь, это сладкий алкогольный напиток, который обычно содержит ароматизаторы, такие как фрукты, травы или специи, и может быть использован в коктейлях или употребляться в чистом виде. Если вам нужна более конкретная информация о каком-то из этих напитков, пожалуйста, уточните ваш вопрос.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mAction: Cocktail Recipe Finder  \n",
      "Action Input: виски, ликер  \u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mВиски — это ароматный напиток, производимый из дистиллята на основе различных видов зерна и выдерживаемый в дубовых бочках. Он может быть ржаным или бурбоном. \n",
      "\n",
      "Ликер — это сладкий алкогольный напиток, который часто содержит фрукты, травы или специи. В контексте вашего запроса, упоминается дынный ликер, который используется в коктейле с текилой и газированной водой.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Результат поиска:\n",
      "Agent stopped due to iteration limit or time limit.\n",
      "Спасибо за использование поиска коктейлей! До свидания!\n"
     ]
    }
   ],
   "source": [
    "# Формирование запроса и вывод результата\n",
    "\n",
    "def main():\n",
    "    print(\"Добро пожаловать в поиск коктейлей!\")\n",
    "\n",
    "    while True:\n",
    "        ingredients = get_user_input()\n",
    "        if not ingredients:\n",
    "            print(\"Вы не ввели ингредиенты. Попробуйте снова.\")\n",
    "            continue\n",
    "\n",
    "        # Формируем текстовый запрос\n",
    "        user_prompt = (\n",
    "            \"\"\"Напиши, какие коктейли можно изготовить из представленных ниже ингредиентов. \n",
    "            Для каждого коктейля опиши подробный способ приготовления и укажи пропорции по представленному ниже примеру. \n",
    "            Отвечай строго на русском языке, используя четкий и лаконичный формат, представленный в примере. \n",
    "            Не добавляй лишнюю информацию, которая не относится к рецепту. \n",
    "            Ответ должен содержать название коктейля, хранимое в базе, и его рецептуру.\n",
    "            Если в запросе указан \"виски\" и \"сок\", то ответ должен быть как в примере. \n",
    "            ===\n",
    "            Пример:\n",
    "                коктейль \"Над пропастью с ржаным\" (на восемь персон):\n",
    "                - 350 мл ржаного виски;\n",
    "                - 120 мл ананасового сока;\n",
    "                - 60 мл лимонного сока;\n",
    "                - 1 л имбирного пива (истинно американский напиток, который непросто отыскать на наших просторах).\n",
    "                Виски и соки заливаем в чашу для пунша, где уже лежит глыба льда.\n",
    "            ===\n",
    "            Ингредиенты: {ingredients}\"\"\".format(ingredients=\", \".join(ingredients))\n",
    "        )\n",
    "\n",
    "\n",
    "        print(\"Запрашиваю информацию...\")\n",
    "        response = agent.run(user_prompt)\n",
    "        print(\"\\nРезультат поиска:\")\n",
    "        print(response)\n",
    "\n",
    "        # Предложение продолжить или завершить\n",
    "        cont = input(\"Хотите выполнить ещё один запрос? (да/нет): \").strip().lower()\n",
    "        if cont != \"да\":\n",
    "            print(\"Спасибо за использование поиска коктейлей! До свидания!\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"## Если не хотите платить денежков, то запустите эту ячейку\n",
    "from langchain.chains import LLMChain\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Считываем ключ из файла\n",
    "with open('../utils.key', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('HUGGINGFACEHUB_API_TOKEN'):\n",
    "            # Извлекаем ключ, убирая лишние пробелы и символы\n",
    "            course_api_key = line.split('=')[1].strip()\n",
    "            break\n",
    "\n",
    "# Создаем объект языкового модели\n",
    "llm = HuggingFaceEndpoint(\n",
    "      #repo_id=\"IlyaGusev/saiga_llama3_8b\",\n",
    "      repo_id=\"mistralai/Mistral-7B-Instruct-v0.3\",\n",
    "      task=\"text-generation\",  # Вид задачи, в нашем случае - генерация текста\n",
    "      huggingfacehub_api_token = course_api_key\n",
    "    )\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\"\"\"\n",
    "\"\"\"# Получаем ответ от модели\n",
    "response = llm(messages).content\n",
    "\n",
    "# Выводим ответ\n",
    "print(\"Рецепт коктейлей:\\n\")\n",
    "print(response)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модифицируем коктейль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используем db_embed для поиска рецептов на основе ингредиентов\n",
    "def search_cocktails_in_db(ingredients_str):\n",
    "    # Здесь вы можете реализовать поиск по вашей базе данных FAISS\n",
    "    # Например, используя векторизацию ингредиентов и выполнение поиска\n",
    "        # Предположим, что у вас есть функция для этого:\n",
    "    results = db_embed.similarity_search(ingredients_str)  # Псевдокод для поиска\n",
    "    return results\n",
    "\n",
    "# Выполняем поиск в базе данных\n",
    "search_results = search_cocktails_in_db(ingredients_str)\n",
    "\n",
    "# Обрабатываем результаты поиска и формируем запрос к агенту\n",
    "if search_results:\n",
    "    # Извлекаем нужные данные из результатов поиска (например, текст документа)\n",
    "    cocktail_names = [result.page_content for result in search_results]  # Используем page_content для получения текста\n",
    "    cocktail_names_str = \", \".join(cocktail_names)\n",
    "    \n",
    "    # Вызываем функцию получения рецептов с найденными коктейлями\n",
    "    response = get_cocktail_recipes(cocktail_names_str, iba_category)\n",
    "else:\n",
    "    response = \"Коктейли не найдены по заданным ингредиентам.\"\n",
    "\n",
    "# Выводим ответ\n",
    "print(\"Рецепт коктейлей:\\n\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Если используем модель с Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# Если выбрали модель с HuggingFace\n",
    "# Объединяем системный и пользовательский промты в одну строку\n",
    "full_prompt = f\"{system_prompt}\\n{user_prompt}\"\n",
    "\n",
    "# Получаем ответ от модели\n",
    "response = llm(full_prompt)\n",
    "\n",
    "# Выводим ответ\n",
    "print(response)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Меняем стиль ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция выбора стиля ответа\n",
    "\n",
    "def choose_style():\n",
    "    styles = {\n",
    "        \"1\": \"стиль космического ужаса и хтонического мрака Говарда Ф. Лавкрафта\",\n",
    "        \"2\": \"гопническо-быдляцкий жаргон\",\n",
    "        \"3\": \"экспериментальный стиль нарезок Уильяма Берроуза\",\n",
    "        \"4\": \"Стиль барного меню\"  # Стиль по умолчанию\n",
    "    }\n",
    "    #print(\"Доступные стили ответа:\")\n",
    "    for key, value in styles.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    chosen_style = input(\"Выберите номер стиля (по умолчанию 4): \") or \"4\"\n",
    "    return styles.get(chosen_style, \"style4\")\n",
    "\n",
    "style = choose_style()\n",
    "prompt = PromptTemplate(input_variables=['output_text', 'style'],\n",
    "                        template='''Перепиши этот текст в заданном стиле: {output_text}\\nСтиль: {style}.\\nРезультат:''')\n",
    "style_changer_chain = prompt | llm\n",
    "\n",
    "styled_response = style_changer_chain.invoke({'output_text': response, 'style': style}).content\n",
    "print(\"\\nОтвет в выбранном стиле:\")\n",
    "print(styled_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разные способы поиска цен на ингредиенты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск с помощью агента\n",
    "1. Инструменты LangChain:\n",
    "    - Мы можем использовать инструменты, такие как `DuckDuckGoSearchRun` (для поиска через DuckDuckGo), или создать собственные инструменты для взаимодействия с API магазинов (например, Winelab, SimpleWine и других).\n",
    "2. Агент LangChain:\n",
    "    - Агент будет обрабатывать запросы, отправлять их в поисковые инструменты и агрегировать ответы.\n",
    "3. Поиск стоимости товара:\n",
    "    - Агент использует инструменты, чтобы найти релевантную информацию о стоимости алкогольных ингредиентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U duckduckgo-search -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Подключение LLM\n",
    "#llm = OpenAI(temperature=0.0, openai_api_key=course_api_key)\n",
    "\n",
    "# Создаем поисковый инструмент DuckDuckGo\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "# Добавляем инструмент в список\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"Search ingredient\",\n",
    "        func=search.run,\n",
    "        description=\"Используйте этот инструмент для поиска информации об ингредиентах и ценах на самые популярные из них.\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# Инициализация агента\n",
    "price_agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    agent=\"zero-shot-react-description\",  # Используем Zero-shot агент\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Формируем промт для поиска цен на товар\n",
    "ingredient = \"бурбон\"\n",
    "city = \"Санкт-Петербург\"\n",
    "prompt = (\n",
    "    f\"Найдите цену на продукт '{ingredient}' в интернет-магазинах {city}. \"\n",
    "    \"\"\"Если вариантов несколько, укажите 3 лучших результата. \n",
    "    Если в ответе название пишется на языке производителя, то оставь как есть. Название валюты и объём должны быть указаны на русском языке. \n",
    "    Укажи ответ в формате: название экземпляра, стоимость в среднем ценовом диапазоне, объём, ссылка на магазин, если имеется; если нет, то ничего не писать. \n",
    "    Если вариантов ответа несколько, то отобрази их в виде вертикального списка, где каждый новый вариант отображается с новой строки. \"\"\"\n",
    ")\n",
    "\n",
    "# Выполнение агента\n",
    "result = price_agent.run(prompt)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск с помощью `RAG`\n",
    "\n",
    "Общая стратегия:\n",
    "\n",
    "1. Использование `WebLoader` для сбора данных:\n",
    "   - скачиваем страницы для каждой категории алкоголя с сайтов, таких как `Winelab`.\n",
    "   - сохраняем их текстовое содержимое (например, названия и цены продуктов) в векторное хранилище.\n",
    "1. Создание векторного хранилища:\n",
    "    - разбиваем загруженные данные на чанки.\n",
    "    - индексируем их с помощью векторизатора (например, FAISS или Chroma).\n",
    "1. Поиск ингредиентов:\n",
    "    - при запросе пользователя (например, \"водка\"), извлекаем соответствующую информацию из хранилища.\n",
    "1. Использование `LangChain`:\n",
    "    - для загрузки данных используем WebBaseLoader из LangChain.\n",
    "    - для индексации данных — инструменты LangChain, такие как Chroma или FAISS.\n",
    "    - для обработки запросов пользователя — цепочки, основанные на LLM (например, `OpenAI API`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install bs4 langchain-openai faiss-cpu -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Установите ваш ключ API\n",
    "# Считываем ключ из файла\n",
    "with open('../utils.key', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('OPENAI_API_KEY'):\n",
    "            # Извлекаем ключ, убирая лишние пробелы и символы\n",
    "            course_api_key = line.split('=')[1].strip()\n",
    "            break\n",
    "\n",
    "# 1. Сбор данных с категорий сайта\n",
    "def fetch_and_index_alcohol_data():\n",
    "    categories = {\n",
    "        \"absinthe\": \"https://www.winelab.ru/catalog/krepkiy-alkogol-absent\",\n",
    "        \"vodka\": \"https://www.winelab.ru/catalog/krepkiy-alkogol-vodka\",\n",
    "        \"whiskey\": \"https://www.winelab.ru/catalog/krepkiy-alkogol-viski\",\n",
    "    }\n",
    "\n",
    "    documents = []\n",
    "    for category, url in categories.items():\n",
    "        try:\n",
    "            loader = WebBaseLoader(url)\n",
    "            category_docs = loader.load()\n",
    "            documents.extend(category_docs)\n",
    "            print(f\"Загружено {len(category_docs)} документов из {url}.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при загрузке данных из {url}: {e}\")\n",
    "\n",
    "    print(f\"Всего загружено документов: {len(documents)}\")\n",
    "    return documents\n",
    "\n",
    "# 2. Разбивка текста на чанки\n",
    "def split_documents(documents):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    chunks = splitter.split_documents(documents)\n",
    "    print(f\"Всего создано чанков: {len(chunks)}\")\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# 3. Индексация данных с использованием FAISS\n",
    "def create_faiss_index(chunks):\n",
    "    if not chunks:\n",
    "        raise ValueError(\"Нет данных для индексации. Проверьте загрузку и разбивку документов.\")\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings(openai_api_key=course_api_key)\n",
    "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "# 4. Создание цепочки RAG для поиска\n",
    "def create_retrieval_chain(vectorstore):\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    llm = OpenAI(temperature=0.0, openai_api_key=course_api_key)\n",
    "    chain = RetrievalQA(llm=llm, retriever=retriever)\n",
    "    return chain\n",
    "\n",
    "# Основная функция\n",
    "def main():\n",
    "    print(\"Сбор данных...\")\n",
    "    documents = fetch_and_index_alcohol_data()\n",
    "    print(\"Разделение на чанки...\")\n",
    "    chunks = split_documents(documents)\n",
    "    print(\"Создание векторного индекса...\")\n",
    "    vectorstore = create_faiss_index(chunks)\n",
    "    print(\"Создание цепочки RAG...\")\n",
    "    rag_chain = create_retrieval_chain(vectorstore)\n",
    "\n",
    "    # Поиск цены ингредиента\n",
    "    ingredient_query = \"водка\"\n",
    "    print(f\"Поиск для: {ingredient_query}\")\n",
    "    result = rag_chain.run(ingredient_query)\n",
    "    print(f\"Результат: {result}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск `в лоб`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "def search_price_with_specific_cookies(ingredient):\n",
    "    \"\"\"\n",
    "    Функция для поиска цен на алкогольные ингредиенты с индивидуальными куки для каждого магазина.\n",
    "    \"\"\"\n",
    "    stores = [\n",
    "        {\n",
    "            \"name\": \"Winelab\",\n",
    "            \"url\": lambda ing: f\"https://www.winelab.ru/search/facets?text={ing}\",\n",
    "            \"cookies\": {\"age-confirmed\": \"1\"},\n",
    "            \"title_pattern\": r'<a class=\"product-card__link\" .*? title=\"(.*?)\"',\n",
    "            \"price_pattern\": r'<div class=\"price__main-value\">(.*?)</div>',\n",
    "            \"link_pattern\": r'<a class=\"product-card__link\" href=\"(.*?)\"',\n",
    "            \"link_prefix\": \"https://www.winelab.ru\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"SimpleWine\",\n",
    "            \"url\": lambda ing: f\"https://simplewine.ru/catalog/?q={ing}\",\n",
    "            \"cookies\": {\"age-confirm\": \"1\"},\n",
    "            \"title_pattern\": r'<a class=\"product-card__title-link\" .*?>(.*?)</a>',\n",
    "            \"price_pattern\": r'<div class=\"product-card__price-current\">(.*?)</div>',\n",
    "            \"link_pattern\": r'<a class=\"product-card__title-link\" href=\"(.*?)\"',\n",
    "            \"link_prefix\": \"https://simplewine.ru\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for store in stores:\n",
    "        try:\n",
    "            headers = {\n",
    "                \"User-Agent\": \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:133.0) Gecko/20100101 Firefox/133.0\"\n",
    "            }\n",
    "            response = requests.get(store[\"url\"](ingredient), headers=headers, cookies=store[\"cookies\"], timeout=5)\n",
    "            if response.status_code == 200:\n",
    "                # Извлечение данных о товарах\n",
    "                titles = re.findall(store[\"title_pattern\"], response.text)\n",
    "                prices = re.findall(store[\"price_pattern\"], response.text)\n",
    "                links = re.findall(store[\"link_pattern\"], response.text)\n",
    "\n",
    "                for title, price, link in zip(titles[:3], prices[:3], links[:3]):\n",
    "                    full_link = f\"{store['link_prefix']}{link}\"\n",
    "                    results.append(f\"- {title.strip()} {price.strip()} рублей {full_link} ({store['name']})\")\n",
    "\n",
    "                if results:\n",
    "                    break  # Если найдены результаты, завершаем поиск\n",
    "            else:\n",
    "                results.append(f\"Ошибка доступа к {store['name']} для {ingredient}: статус {response.status_code}\")\n",
    "        except Exception as e:\n",
    "            results.append(f\"Ошибка при выполнении поиска в {store['name']} для {ingredient}: {str(e)}\")\n",
    "\n",
    "    if not results:\n",
    "        results.append(f\"Данные о наличии в продаже {ingredient} не найдены.\")\n",
    "\n",
    "    return \"\\n\".join(results)\n",
    "\n",
    "# Пример использования\n",
    "ingredient_name = \"джин\"\n",
    "print(search_price_with_specific_cookies(ingredient_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разбор коктейля и ингредиентов для поиска цен\n",
    "pattern = r\"\\*\\*(.*?)\\*\\*:.*?((?:\\n\\s*-\\s*.*?\\n)+)\"\n",
    "match = re.search(pattern, response, re.DOTALL)\n",
    "if match:\n",
    "    cocktail_name = match.group(1)\n",
    "    ingredients_section = match.group(2)\n",
    "    print(f\"\\nКоктейль: {cocktail_name}\")\n",
    "    print(f\"Ингредиенты:\")\n",
    "    print(ingredients_section)\n",
    "    \n",
    "    # Поиск цен для каждого ингредиента\n",
    "    ingredient_lines = ingredients_section.strip().split(\"\\n\")\n",
    "    for line in ingredient_lines:\n",
    "        ingredient_match = re.search(r\"-\\s*\\d+\\s*мл\\s*([^\\n]+)\", line)\n",
    "        if ingredient_match:\n",
    "            ingredient_name = ingredient_match.group(1)\n",
    "            print(f\"\\nИщем цену для: {ingredient_name}\")\n",
    "            prices = search_price(ingredient_name)\n",
    "            print(prices)\n",
    "        else:\n",
    "            print(f\"\\nНе удалось извлечь название ингредиента из строки: {line}\")\n",
    "else:\n",
    "    print(\"Не удалось найти информацию о коктейле и ингредиентах в ответе модели.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Поиск с помощью Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install selenium -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "def search_price_with_selenium(ingredient):\n",
    "    \"\"\"\n",
    "    Поиск цен на ингредиенты с использованием Selenium.\n",
    "    \"\"\"\n",
    "    # Укажите путь к вашему WebDriver\n",
    "    service = Service('/home/elijah/Documents/chromedriver-linux64/chromedriver')  # Укажите корректный путь к ChromeDriver\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--headless\")  # Запуск в безголовом режиме\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-gpu\")\n",
    "\n",
    "    driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "    results = []\n",
    "    try:\n",
    "        # Магазин Winelаб\n",
    "        driver.get(\"https://www.winelab.ru\")\n",
    "\n",
    "        # Подтверждение возраста\n",
    "        age_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.CLASS_NAME, \"age-confirm\"))\n",
    "        )\n",
    "        age_button.click()\n",
    "\n",
    "        # Поиск ингредиента\n",
    "        search_box = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.NAME, \"text\"))  # Обратите внимание на имя поля\n",
    "        )\n",
    "\n",
    "        # Добавление небольшой задержки для обеспечения доступности элемента\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Используем JavaScript для установки значения в поле ввода\n",
    "        driver.execute_script(\"arguments[0].value = arguments[1];\", search_box, ingredient)\n",
    "        \n",
    "        # Теперь вызываем событие input для имитации ввода текста\n",
    "        search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "        # Найдите кнопку отправки и нажмите ее (если это необходимо)\n",
    "        # search_button = driver.find_element(By.CLASS_NAME, \"js_search_button\")\n",
    "        # search_button.click()\n",
    "\n",
    "        # Сбор результатов\n",
    "        products = WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_all_elements_located((By.CLASS_NAME, \"product-card\"))\n",
    "        )\n",
    "        \n",
    "        for product in products[:3]:  # Берём максимум 3 результата\n",
    "            title = product.find_element(By.CLASS_NAME, \"product-card__title\").text\n",
    "            price = product.find_element(By.CLASS_NAME, \"price__main-value\").text\n",
    "            \n",
    "            results.append(f\"- {title} {price.strip()} рублей\")\n",
    "\n",
    "    except Exception as e:\n",
    "        results.append(f\"Ошибка при обработке ингредиента {ingredient}: {str(e)}\")\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    return results if results else f\"Данные о наличии в продаже {ingredient} не найдены.\"\n",
    "\n",
    "# Пример использования\n",
    "ingredient_name = \"водка\"\n",
    "print(search_price_with_selenium(ingredient_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
