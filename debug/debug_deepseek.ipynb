{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Импорт и определение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отключение параллелизма\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ставим разные пакеты оттуда\n",
    "!pip install langchain langchain-openai langchain-community openai tiktoken langchain-huggingface -q\n",
    "!pip install beautifulsoup4 pypdf sentence-transformers faiss-cpu unstructured pypandoc -q\n",
    "#huggingface_hub  langchain_experimental langchainhub\n",
    "#!pip install unstructured \"unstructured[pdf]\" -q\n",
    "!pip install sentence-transformers numpy transformers requests -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "/home/elijah/Documents/LLM/cocktail_qr/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# импортируем библиотеки\n",
    "from langchain.document_loaders import WebBaseLoader, PyPDFLoader, UnstructuredEPubLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.prompts import PromptTemplate\n",
    "import tqdm as notebook_tqdm\n",
    "from huggingface_hub import HfApi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Готовим коктейль с помощью RAG\n",
    "## Чутка `embeddings` с `HuggingFace` для оснастки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение токена из файла\n",
    "def read_token(file_path): \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith(\"HUGGINGFACEHUB_API_TOKEN\"):\n",
    "                return line.split('=')[1].strip()\n",
    "    raise ValueError(\"Token not found in the specified file.\")\n",
    "\n",
    "# Загрузка токена\n",
    "hf_token = read_token('../.env')\n",
    "\n",
    "# Формирование эмбеддингов\n",
    "hf_embeddings_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"cointegrated/LaBSE-en-ru\",  \n",
    "    #\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\", \n",
    "    #\"cointegrated/LaBSE-en-ru\",\n",
    "    model_kwargs={\n",
    "        \"device\": \"cpu\",\n",
    "        \"token\": hf_token\n",
    "                  },\n",
    "    encode_kwargs={\n",
    "        'normalize_embenddings': True\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Можно пропустить (если используете наполненную чашу векторного хранилища)\n",
    "### Немного `Document Loader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pages count: 1\n",
      "max chars on page: 107261\n"
     ]
    }
   ],
   "source": [
    "# Загрузка EPUB файла от бармена-литературоведа\n",
    "loader = UnstructuredEPubLoader('../docs/Federle.epub', show_progress=True)\n",
    "doc_epub = loader.load()\n",
    "\n",
    "# смотрим, скока получилось загрузить\n",
    "print('pages count:', len(doc_epub))\n",
    "print('max chars on page:', max([len(page.page_content) for page in doc_epub]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем книгу от крутого бармена\n",
    "#loader = WebBaseLoader(url)\n",
    "\"\"\"loader = PyPDFLoader('../docs/Bortnik_1000.pdf')\n",
    "data = loader.load()\n",
    "\n",
    "print('pages count:', len(data))\n",
    "print('max chars on page:', max([len(page.page_content) for page in data]))\"\"\"\n",
    "\n",
    "# на тот случай, если решим загружать подобную литературу пачкой pdf\n",
    "\"\"\"\n",
    "#!pip install unstructured \"unstructured[pdf]\" -q\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "loader = DirectoryLoader(\"../docs\", glob=\"**/*.pdf\", show_progress=True)\n",
    "data = loader.load()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Исполним `Text splitters` и разобьём на чанки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Точная токенизация под `DeepSeek`**\n",
    "\n",
    "- Кастомный класс `TransformersTokenSplitter`:\n",
    "  - принимает токенизатор `Hugging Face`.\n",
    "  - токенизирует текст с помощью `tokenizer.encode()`.\n",
    "  - разбивает токены на чанки с учетом `chunk_size` и `chunk_overlap`.\n",
    "  - декодирует чанки обратно в текст через `tokenizer.decode()`.\n",
    "\n",
    "- Особенности:\n",
    "  - точное соответствие токенизации модели `DeepSeek`.\n",
    "  - сохранение перекрытия между чанками.\n",
    "  - поддержка любых токенизаторов из `Transformers`.\n",
    "\n",
    "- Почему это лучше стандартного `TokenTextSplitter`:\n",
    "  - точность: используется токенизатор, идентичный модели.\n",
    "  - гибкость: работает с любыми моделями `Hugging Face`.\n",
    "  - контроль: позволяет задавать параметры в токенах, а не символах.\n",
    "  \n",
    "Сравнение подходов:\n",
    "| Параметр | Решение 1 (Символы) | Решение 2 (Токены)|\n",
    "|---|---|---|\n",
    "| Точность | Средняя\t| Высокая |\n",
    "|Производительность\t | Быстрее\t| Медленнее (токенизация) |\n",
    "|Сложность\t| Просто\t| Требует токенизатор |\n",
    "|Рекомендация\t| Для общего случая\t| Для точного контекста |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List  # Добавляем импорт для List\n",
    "from langchain.text_splitter import TextSplitter\n",
    "\n",
    "class RecipeBasedSplitter(TextSplitter):\n",
    "    def __init__(self):\n",
    "        super().__init__(chunk_size=1000, chunk_overlap=300)\n",
    "    \n",
    "    def split_text(self, text: str) -> List[str]:\n",
    "        # Убираем все пустые строки и лишние пробелы\n",
    "        cleaned_text = \"\\n\".join([line.strip() for line in text.split(\"\\n\") if line.strip()])\n",
    "        \n",
    "        # Разделяем текст на рецепты по маркеру \"НАЗВАНИЕ_РЕЦЕПТА\\nАВТОР\"\n",
    "        recipes = []\n",
    "        current_recipe = []\n",
    "        lines = cleaned_text.split(\"\\n\")\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(lines):\n",
    "            line = lines[i]\n",
    "            # Проверяем начало нового рецепта\n",
    "            if i + 1 < len(lines) and lines[i+1].isupper() and \"(\" in lines[i+1] and \")\" in lines[i+1]:\n",
    "                if current_recipe:\n",
    "                    recipes.append(\"\\n\".join(current_recipe))\n",
    "                    current_recipe = []\n",
    "                current_recipe.append(line)\n",
    "                current_recipe.append(lines[i+1])\n",
    "                i += 2\n",
    "                continue\n",
    "            \n",
    "            current_recipe.append(line)\n",
    "            i += 1\n",
    "        \n",
    "        if current_recipe:\n",
    "            recipes.append(\"\\n\".join(current_recipe))\n",
    "        \n",
    "        # Разбиваем каждый рецепт на чанки\n",
    "        chunks = []\n",
    "        for recipe in recipes:\n",
    "            # Используем собственную логику разбиения текста на чанки\n",
    "            recipe_chunks = self._split_recipe_into_chunks(recipe)\n",
    "            chunks.extend(recipe_chunks)\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def _split_recipe_into_chunks(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Внутренний метод для разбиения текста на чанки.\n",
    "        \"\"\"\n",
    "        chunks = []\n",
    "        current_chunk = []\n",
    "        current_length = 0\n",
    "        \n",
    "        lines = text.split(\"\\n\")\n",
    "        for line in lines:\n",
    "            line_length = len(line)\n",
    "            \n",
    "            # Если добавление новой строки превышает размер чанка\n",
    "            if current_length + line_length > self._chunk_size:\n",
    "                chunks.append(\"\\n\".join(current_chunk))\n",
    "                current_chunk = current_chunk[-self._chunk_overlap:]  # Сохраняем перекрытие\n",
    "                current_length = sum(len(line) for line in current_chunk)\n",
    "            \n",
    "            current_chunk.append(line)\n",
    "            current_length += line_length\n",
    "        \n",
    "        if current_chunk:\n",
    "            chunks.append(\"\\n\".join(current_chunk))\n",
    "        \n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество чанков: 305\n",
      "Максимальное количество символов в чанке: 15125\n"
     ]
    }
   ],
   "source": [
    "# Инициализация сплиттера\n",
    "splitter = RecipeBasedSplitter()\n",
    "\n",
    "# Разделяем документ на чанки\n",
    "chunks = splitter.split_documents(doc_epub)\n",
    "\n",
    "print('Количество чанков:', len(chunks))\n",
    "print('Максимальное количество символов в чанке:', max([len(chunk.page_content) for chunk in chunks]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Наполним чашу `Vector Store`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если нужно сохранить новый документ в базу\n",
    "try:\n",
    "    db_embed = FAISS.from_documents(\n",
    "            chunks, \n",
    "            hf_embeddings_model\n",
    "        )\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"Ошибка при создании базы данных FAISS: {e}\")\n",
    "\n",
    "\n",
    "# Сохраняем векторную базу локально\n",
    "db_embed.save_local(\"../data/faiss_db_epub_deepseek\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нужно запустить (если используете готовое векторное хранилище)\n",
    "### Испьём чашу `Vector Store`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Если нужно изъять из уже сохранённого документа из базы\n",
    "# Загрузка векторной базы данных из локального файла\n",
    "db_embed = FAISS.load_local(\n",
    "        \"../data/faiss_db_epub_deepseek\", \n",
    "        hf_embeddings_model,\n",
    "        allow_dangerous_deserialization = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Моя комната – мой ром\n",
      "СВОЯ КОМНАТА (1929)\n",
      "ВИРДЖИНИЯ ВУЛФ\n",
      "Вирджиния, Вирджиния… Такая умная, даровитая. Такая печальная. Такая… особенная. Как утверждает наша миссис, женщине, чтобы писать художественную прозу, нужны своя комната и пятьсот фунтов в год. (О нехудожественной прозе Вулф ничего такого не говорила, из чего можно сделать вывод, что, если вас влечет журналистская стезя, можно не иметь за душой ни гроша и ютиться вчетвером в крохотной квартирке-студии.) И хотя предложенный Вирджинией рецепт писательского успеха безупречен, рискнем все-таки добавить к нему симпатичный штришок в виде согревающего душу и тело коктейля. Рекомендуется для морозных зимних ночей, когда приходит писательское вдохновение. С таким горячим коктейлем и мужчина под боком не нужен!\n",
      "½ чайной ложки (2,5 г) мягкого соленого сливочного масла;\n",
      "1 чайная ложка (5 г) тростникового сахара;\n",
      "½ чайной ложки (2,5 г) молотой корицы;\n",
      "60 мл темного рома.\n",
      "Сговор «Сазераков»\n",
      "СГОВОР ОСТОЛОПОВ (1980)\n",
      "ДЖОН КЕННЕДИ ТУЛ\n",
      "Только после самоубийства Джона Кеннеди Тула его мать узнала, что сын втайне от всех написал роман, – и сразу принялась обивать пороги издательских домов Луизианы, убеждая, что это алмаз американской прозы. (Вот так-то, друзья, и матери иногда бывают правы!) Этот увенчанный Пулитцеровской премией роман о причуднике из Нового Орлеана гармонично сочетается с такой же знаменитой новоорлеанской достопримечательностью – коктейлем «Сазерак». Итак, за безвременно покинувшего нас писателя – и за произведения, которые он мог бы нам оставить!\n",
      "15 мл анисового ликера (например, «Хербсайнт»);\n",
      "50 мл ржаного виски;\n",
      "1 чайная ложка (5 г) сахара;\n",
      "3 дэша биттера «Пишо» (Pechaud);\n",
      "2 дэша биттера «Ангостура»;\n",
      "завиток (твист) цедры лимона для украшения.\n",
      "Преступление и мятное наказание\n",
      "ПРЕСТУПЛЕНИЕ И НАКАЗАНИЕ (1866)\n",
      "ФЕДОР МИХАЙЛОВИЧ ДОСТОЕВСКИЙ\n",
      "Когда главный герой сравнивает себя с Наполеоном, да еще и в свою пользу, с первой же страницы понимаешь, что закадровый смех здесь неуместен. Читатели, впервые взявшиеся за «Преступление и наказание» – мучительно-болезненную историю о молодом человеке, возомнившем себя вправе убить старушку-процентщицу и по своему разумению перераспределить ее богатство, – чего доброго заподозрят, что перед ними литературная основа «Закона и порядка». И ошибутся. Преступление? Безусловно! Наказание? А вот тут нет: забудьте и думать о сценах из полицейских сериалов, где зло немедленно получает по заслугам; в романе главным наказанием преступнику будет пожизненное осознание своей вины. Соединим же самый русский напиток – да-да, именно водку – с изрядной дозой кофеина: для хорошей встряски; ну а мята пусть обуздает ваши страсти, прежде чем вы вздумаете выкинуть что-нибудь совсем уж из ряда вон:\n",
      "50 мл водки;\n",
      "20 мл кофейного ликера;\n",
      "15 мл мятного ликера;\n",
      "нежирные сливки.\n"
     ]
    }
   ],
   "source": [
    "query = \"90 мл грейпфрутового сока 50 мл ржаного виски.\"\n",
    "results = db_embed.similarity_search(query, k=3)\n",
    "for result in results:\n",
    "    print(result.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Месье системный промт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Системный промпт\n",
    "system_prompt = \"\"\"Ты — помощник для поиска рецептов коктейлей. Используй только данные из контекста ниже:\n",
    "        {context}\n",
    "\n",
    "        Пример:\n",
    "        Пользователь: Какие коктейли можно сделать из водки и апельсинового сока?\n",
    "        Агент: Использую инструмент \"Cocktail Recipe Finder\" для поиска рецептов. Вот что найдено: [рецепт].\n",
    "\n",
    "        **Строгий формат ответа**:\n",
    "        1. Название коктейля (только одно уникальное название из источника)\n",
    "        2. Состав:\n",
    "        - Ингредиент 1 (объем)\n",
    "        - Ингредиент 2 (объем)\n",
    "        3. Способ приготовления:\n",
    "        - Шаг 1\n",
    "        - Шаг 2\n",
    "\n",
    "        **Запрещено**:\n",
    "        - Добавлять описание вкуса, аромата или эмоций\n",
    "        - Использовать сложные термины (например, \\\"вкусовые соединения\\\")\n",
    "        - Создавать варианты в скобках\n",
    "\n",
    "        Пример корректного ответа по введённым ингредиентам (ржаной виски, грейпфрутовый сок):\n",
    "        Коктейль \"Рожь и предубеждение\"\n",
    "        Состав:\n",
    "        - Ржаной виски (50 мл)\n",
    "        - Грейпфрутовый сок (90 мл)\n",
    "        Способ приготовления:\n",
    "        - Ингредиенты выливаем в стакан рокс поверх кубиков льда\"\"\"\n",
    "\n",
    "# Промпт для LangChain\n",
    "qa_prompt = PromptTemplate(\n",
    "    template=system_prompt + \"\\nВопрос: {question}\\nОтвет:\",\n",
    "    input_variables=[\"context\", \"question\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Полирнём `Retriver` и инициализирует `llm` для вкуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain ollama -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация модели DeepSeek\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Инициализация модели через Ollama\n",
    "llm = Ollama(\n",
    "    model=\"deepseek-llm:7b-chat\",\n",
    "    temperature=0.3,        # Увеличиваем для большей креативности\n",
    "    num_predict=512,        # Уменьшаем длину ответа\n",
    "    repeat_penalty=1.2,     # Усиливаем штраф за повторы\n",
    "    #top_p=0.9,              # Для фокусировки\n",
    "    #top_k=40,               # Ограничиваем выбор токенов\n",
    "    stop=[\"\\\\n\\\\n\"]         # Остановка при двойных переносах\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модифицируем параметры ретривера\n",
    "retriever = db_embed.as_retriever(\n",
    "    search_type=\"mmr\",              # Maximal Marginal Relevance\n",
    "    search_kwargs={\n",
    "        \"k\": 3,                     # Уменьшаем количество возвращаемых документов\n",
    "        \"fetch_k\": 10,              # Уменьшаем общий пул для поиска\n",
    "        \"lambda_mult\": 0.6          # Баланс между релевантностью и разнообразием\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# Инициализация цепочки RetrievalQA\n",
    "retrieval_qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    retriever=retriever,  # Ваш ретривер (например, FAISS)\n",
    "    chain_type_kwargs={\"prompt\": qa_prompt},\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Миксуем рецепт коктейля `agent` 00х"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание инструмента\n",
    "agent_tools = [\n",
    "    Tool(\n",
    "        name=\"Cocktail Recipe Finder\",\n",
    "        func=retrieval_qa.run,\n",
    "        description=\"Используй этот инструмент, чтобы найти рецепты коктейлей по заданным ингредиентам. Вводи список ингредиентов, и инструмент вернёт подходящие рецепты. Пример: ['сок', 'виски'].\"\n",
    "    )\n",
    "]\n",
    "\n",
    "# создание агента\n",
    "agent = initialize_agent(\n",
    "    tools=agent_tools, \n",
    "    llm=llm, \n",
    "    agent=\"conversational-react-description\",       #\"zero-shot-react-description\", \"plan-and-execute\"\n",
    "    verbose=True,\n",
    "    system_prompt=system_prompt                     # не забыть указать системный промт для вкуса\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задаём общие параметры, после чего коктейль готов\n",
    "## Вначале коктейль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объявление функции на ввод данных от пользователя\n",
    "def get_user_input():\n",
    "    \"\"\"\n",
    "    Запрашивает у пользователя ингредиенты для поиска рецептов.\n",
    "    \"\"\"\n",
    "    user_input = input(\"Введите ингредиенты, разделенные запятыми: \")\n",
    "    ingredients = [ingredient.strip() for ingredient in user_input.split(\",\")]\n",
    "    return ingredients\n",
    "\n",
    "\n",
    "# Обработка ответа\n",
    "def format_response(response):\n",
    "    if \"не знаю\" in response.lower() or \"не найдено\" in response.lower():\n",
    "        return \"К сожалению, я не нашёл коктейлей с этими ингредиентами. Попробуйте другие ингредиенты.\"\n",
    "    else:\n",
    "        return response\n",
    "    \n",
    "\n",
    "# Функция выбора стиля ответа\n",
    "def choose_style(styles):\n",
    "    chosen_style = input(\"Выберите номер стиля (по умолчанию 4): \") or \"4\"\n",
    "    return styles.get(chosen_style, \"по-умолчанию\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Бурбон в летнюю ночь (ок. 1600)\n",
      "    * Шеекер\n",
      "      - 50 мл дешевого виски; сплэш ананасового сока (это означает плеснуть 5–10 мл); шлепок кокосовых сливок.\n",
      "      - Ингредиенты наливаем поверх кубиков льда в стакан рокс (впрочем, подойдет и туристическая кружка). Энергично перемешиваем, хватаем с полки \"Таитянский для начинающих\" и мчим в аэропорт!\n",
      "2. Прощай, \"Амаретто\"! (1929)\n",
      "    * Шеекер\n",
      "      - 60 мл водки; 15 мл сока лайма; ½ чайной ложки (2,5 г) вустерского соуса; ½ чайной ложки (2,5 г) васаби; 12–15 капель острого соуса (3 дэша на языке барменов); соль и перец по вкусу.\n",
      "      - Все ингредиенты соединяем в шейкер с льдом. От души взбалтываем и процеживаем через стрейнер в стакан коллинз на свежеприготовленный лед. Поборники традиций украшают напиток стебельком сельдерея, но если вы любите \"погорячее\", то просто удвойте порцию васаби.\n",
      "3. Говардс-бленд (1910)\n",
      "    * Форстэсер\n",
      "      - Эдвин Морган Фостер\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Стилевые инструкции с акцентом на общие характеристики\n",
    "    style_instructions = {\n",
    "        \"1\": {\n",
    "            \"name\": \"Космический ужас Лавкрафта\",\n",
    "            \"description\": (\n",
    "                \"Используй архаичную лексику, метафоры древних сил и непостижимых существ. \"\n",
    "                \"Допустимые элементы: нектар тьмы, дрожащие ингредиенты, запретные ритуалы. \"\n",
    "                \"Избегай бытовых описаний.\"\n",
    "            ),\n",
    "            \"params\": {\"temperature\": 0.8, \"top_p\": 0.85}\n",
    "        },\n",
    "        \"2\": {\n",
    "            \"name\": \"Гопническо-быдляцкий жаргон\",\n",
    "            \"description\": (\n",
    "                \"Используй грубую лексику, просторечия и абсурдные сравнения. \"\n",
    "                \"Примеры: 'замути', 'вмазать', 'как пацанчик'. \"\n",
    "                \"Сокращай предложения.\"\n",
    "            ),\n",
    "            \"params\": {\"temperature\": 0.9, \"top_p\": 0.95}\n",
    "        },\n",
    "        \"3\": {\n",
    "            \"name\": \"Экспериментальный стиль Берроуза\",\n",
    "            \"description\": (\n",
    "                \"Разрывай текст на фрагменты, используй нелинейность и аллюзии. \"\n",
    "                \"Пример: 'Шейкер*вибрация*льдинки-глаза*взрыв*смешение'.\"\n",
    "            ),\n",
    "            \"params\": {\"temperature\": 1.0, \"top_p\": 0.99}\n",
    "        },\n",
    "        \"4\": {\n",
    "            \"name\": \"Стандартный\",\n",
    "            \"description\": \"Без изменений\",\n",
    "            \"params\": {\"temperature\": 0.0, \"top_p\": 0.95}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        ingredients = get_user_input()\n",
    "        if not ingredients:\n",
    "            print(\"Вы не ввели ингредиенты. Попробуйте снова.\")\n",
    "            continue\n",
    "\n",
    "        # Базовый запрос\n",
    "        ingredients_str = \", \".join(ingredients)\n",
    "        user_prompt = f\"\"\"\n",
    "        Найди рецепты коктейлей по ингредиентам: {ingredients_str}\n",
    "        Учти соответствие с системным промтом и стилистикой ответа.\n",
    "        \"\"\"\n",
    "\n",
    "        response = retrieval_qa.invoke({\"query\": user_prompt})\n",
    "        original_response = response[\"result\"]\n",
    "\n",
    "        # Выбор стиля\n",
    "        chosen_style = input(\"Выберите стиль (1-4): \") or \"4\"\n",
    "        style_config = style_instructions.get(chosen_style, style_instructions[\"4\"])\n",
    "        \n",
    "        # Промпт для стилизации\n",
    "        style_prompt = f\"\"\"Перепиши этот текст в заданном стиле: {original_response}\\nСтиль: {style_instructions}.\\nРезультат:\\n''\n",
    "        \"\"\"\n",
    "\n",
    "        # Генерация с настройками стиля\n",
    "        styled_response = llm.invoke(\n",
    "            style_prompt,\n",
    "            temperature=style_config[\"params\"][\"temperature\"],\n",
    "            top_p=style_config[\"params\"][\"top_p\"]\n",
    "        )\n",
    "\n",
    "        # Постобработка\n",
    "        styled_response = styled_response.strip()\n",
    "\n",
    "        print(styled_response)\n",
    "        break\n",
    "\n",
    "    return styled_response\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Сохраняем результат в переменную\n",
    "    recipe = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теперь озвучка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импортируем библиотеки\n",
    "import requests\n",
    "import uuid\n",
    "\n",
    "# функция для получения токена\n",
    "def get_token(auth_token, scope='SALUTE_SPEECH_PERS'):\n",
    "    \"\"\"\n",
    "      Выполняет POST-запрос к эндпоинту, который выдает токен.\n",
    "\n",
    "      Параметры:\n",
    "      - auth_token (str): токен авторизации, необходимый для запроса.\n",
    "      - область (str): область действия запроса API. По умолчанию — «SALUTE_SPEECH_PERS».\n",
    "\n",
    "      Возвращает:\n",
    "      - ответ API, где токен и срок его \"годности\".\n",
    "      \"\"\"\n",
    "    # Создадим идентификатор UUID (36 знаков)\n",
    "    rq_uid = str(uuid.uuid4())\n",
    "\n",
    "    # API URL\n",
    "    url = \"https://ngw.devices.sberbank.ru:9443/api/v2/oauth\"\n",
    "\n",
    "    # Заголовки\n",
    "    headers = {\n",
    "        'Content-Type': 'application/x-www-form-urlencoded',\n",
    "        'RqUID': rq_uid,\n",
    "        'Authorization': f'Basic {auth_token}'\n",
    "    }\n",
    "\n",
    "    # Тело запроса\n",
    "    payload = {\n",
    "        'scope': scope\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # Делаем POST запрос с отключенной SSL верификацией\n",
    "        # (можно скачать сертификаты Минцифры, тогда отключать проверку не надо)\n",
    "        response = requests.post(url, headers=headers, data=payload, verify=False)\n",
    "        return response\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Ошибка: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Прочитанное значение: 'MTVjODUyZDMtZTU2Mi00ZWY5LWI3YzctZGY4YjUxZGMzMjhjOjllZmQ3NjZmLTVhYWQtNGYxOC1iN2I4LTQwOGMyY2IwZWI4Yg=='\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elijah/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ngw.devices.sberbank.ru'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Считываем ключ авторизации из файла\n",
    "with open('../utils.key', 'r') as file:\n",
    "    for line in file:\n",
    "        if line.startswith('SBER_API_KEY'):\n",
    "            SBER_API_KEY = line.split('=', 1)[1].strip(' \\n\\r')\n",
    "            if not SBER_API_KEY.endswith('=='):  # Если нет ==, добавляем их\n",
    "                SBER_API_KEY += '=='\n",
    "            break\n",
    "\n",
    "print(f\"Прочитанное значение: '{SBER_API_KEY}'\")\n",
    "#'MTVjODUyZDMtZTU2Mi00ZWY5LWI3YzctZGY4YjUxZGMzMjhjOjllZmQ3NjZmLTVhYWQtNGYxOC1iN2I4LTQwOGMyY2IwZWI4Yg=='\n",
    "\n",
    "response = get_token(SBER_API_KEY) # получаем токен\n",
    "if response != None:\n",
    "    salute_token = response.json()['access_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция для синтеза речи\n",
    "def synthesize_speech(text, token, format='wav16', voice='May_24000'):\n",
    "    url = \"https://smartspeech.sber.ru/rest/v1/text:synthesize\" # URL для синтеза речи\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {token}\", # токен авторизации\n",
    "        \"Content-Type\": \"application/text\" # тип содержимого\n",
    "    }\n",
    "    params = {\n",
    "        \"format\": format, # формат аудио\n",
    "        \"voice\": voice # голос\n",
    "    }\n",
    "    response = requests.post(\n",
    "            url, \n",
    "            headers=headers, \n",
    "            params=params, \n",
    "            data=text.encode(), # текст для синтеза\n",
    "            verify=False # отключение проверки SSL\n",
    "        )\n",
    "\n",
    "    # проверка на успешность синтеза\n",
    "    if response.status_code == 200:\n",
    "        # Сохранение синтезированного аудио в файл\n",
    "        with open('output.wav', 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        print(\"Аудио успешно синтезировано и сохранено как 'output.wav'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elijah/Documents/LLM/cocktail_qr/.venv/lib/python3.12/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'smartspeech.sber.ru'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Аудио успешно синтезировано и сохранено как 'output.wav'\n"
     ]
    }
   ],
   "source": [
    "# вызов функции для синтеза речи\n",
    "synthesize_speech(recipe, salute_token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
