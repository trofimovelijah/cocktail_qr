# ~~Всратое~~ путешествие в мир коктейлей
## Замысел ~~Отель `У погибшего пессимиста`~~
Изначально у меня была идея реализовать возможность поиска по, главным образом, алкогольным коктейлям, исходя из наличия имеющихся у пользователя ин~~ди~~гредиентов. А чтобы он мог сохранять свои находки, можно было реализовать функцию генерации `QR` кода. Однако в ходе предпроектного анализа выяснилось, что подобная возможность не будет востребованной по ряду причин. В связи с этим было решено вместо генерации кодов (к этой идее возможно мы вернёмся впоследствие) реализовать озвучку рецептов. А поскольку имеющиеся возможности синтеза речи не очень хорошо (скорее всего, это реализуемо) воспроизводят интонацию и эмоции, то при прослушивании результата пользователь улыбнётся, покажет/перешлёт товарищу рецепт, и, тем самым, запомнит, что можно сделать из имеющейся под руками алкашки. 

## Основные возможности
### Принципы функционирования приложения в целом
1. Поиск коктейлей своеобразно ведётся по книге `Мастер шейков и «Маргариты». Коктейли для запойных читателей` Тима Федерле
2. Документ разбит на чанки с оптимизацией под выбранную модель
3. Используется многоязычная модель эмбеддингов `paraphrase-multilingual-mpnet-base-v2` 
4. Агент LLM (на базе `Mistral-7B-Instruct-v0.3`) осуществляет подбор коктейлей по имеющимся ингредиентам
5. Синтез речи с помощью модели `snakers4/silero-models`
6. Ответ синтезируется в речь методом синхронного синтеза. Синхронный подход обоснован необходимостью блокировки выполнения программы до завершения запроса в очереди, что опосредованно влияет на расход дорогостоящих токенов.

### Технические возможности
1. В ходе отладки приложения было проведено исследование функционирование агента с различными моделиями:
   - проприетарными моделями от [OpenAI](/debug/debug_chatgpt.ipynb) (`gpt-3.5-turbo` / `gpt-4o-mini`)
   - моднейшем модели [deepseek-llm-7b-chat](/debug/debug_deepseek.ipynb)
   - модели [ mistral-7B-instruct-v0.3](/debug/debug_mistral.ipynb) (Q4_0)
2. Аналогично также был опробован синтез текста с помощью моделей:
   - проприетарной модели [SaluteSpeech](/debug/synthesize_salutspeech.ipynb)
   - модели с открытым кодом [Silero](/debug/synthesize_silero.ipynb)

### Пользовательские возможности
1. Возможность осуществить поиск коктейля по имеющимся ~~в заначке~~ ингредиентам
2. Отображение ответа рецептов коктейлей в выбранном стиле в одном из 4-х стилей
3. Возможность прослушать полученный вариант ответа
4. Стиль ответа (звук, текст) отличается в зависимости от выбора


## Предварительные шаги при развёртывании
1. Перед использованием необходимо в корневой директории создать файл `.env` и поместить в него ключи от `OpenAI` и `huggingFace` в формате:  
   ```
    - HUGGINGFACEHUB_API_TOKEN = ключ
    - TELEGRAM_BOT_TOKEN=YOUR_TELEGRAM_BOT_TOKEN_HERE
    # опционально
    - SBER_API_KEY = ключ_авторизации
    - OPENAI_API_KEY = ключ
   ```
2. Ежели решили использовать запуск моделей локальных, чтобы денежку не тратить зазря, тогда необходимо предварительно запустить модель. Например, 
   ```bash
   ollama run mistral:instruct
   ``` 

## Требования к системе
- Python 3.12+
- Docker
- Локально установленная модель Ollama для работы без API
- свободное место под образ сборки ~14 Гб
- Установленные зависимости из requirements.txt:
  - python-telegram-bot
  - python-dotenv
  - langchain и связанные пакеты
  - faiss-cpu
  - sentence-transformers
  - torch и torchaudio
  - silero
  - ollama

## Порядок развёртывания
1. Клонировать репозиторий:
   ```bash
   git clone <repository_url>
   cd cocktail_qr
   ```

2. Запустить и активировать виртуальное окружение (необязательно)
   ```
   python3 -m venv .venv
   source .venv/bin/activate
   ```
3. Создать файл `.env` в корневой директории с необходимыми ключами:
   ```
   TELEGRAM_BOT_TOKEN=your_telegram_bot_token
   HUGGINGFACEHUB_API_TOKEN=your_huggingface_token
   ```

4. Запустить локальную модель Ollama (если планируется использовать):
   ```bash
   ollama run mistral:instruct
   ```

5. Выполнить локальную сборку контейнера
   ```bash
   docker build -t cocktail_bot .
   ```
6. Запустить контейнер (с просмотром логов)
   ```bash
   docker run -it --rm cocktail_bot
   ```
7. Альтернативный запуск == Собрать и запустить контейнер:
   ```bash
   # docker-compose up --build
   ```

## Стили отображения рецептов
Доступны следующие стили вывода рецептов:
1. Стиль космического ужаса (Г.Ф. Лавкрафт)
2. Гопническо-быдляцкий жаргон
3. Экспериментальный стиль У. Берроуза
4. Классический стиль (по умолчанию)

## Структура проекта
```
cocktail_qr/
├── Dockerfile
├── docker-compose.yml
├── requirements.txt
├── .env
├── models/
│   ├── __init__.py
│   ├── recipe_finder.py    # Логика поиска рецептов
│   ├── speech_generator.py # Логика генерации речи
│   └── telegram_bot.py     # Основной код бота
├── data/
│   └── faiss_db_epub_mistral/ # Векторное хранилище
├── docs/
│   └── recipes/            # Файлы с рецептами
├── debug/                  # Тетради-ноутбуки для отладки различных решений
└── audio/                  # Директория для аудиофайлов
```

## Особенности реализации
1. **Архитектура бота**:
   - Синхронная работа через ConversationHandler
   - Модульная структура с разделением ответственности
   - Сохранение контекста разговора в user_data

2. **Пользовательский интерфейс**:
   - Пошаговый ввод ингредиентов с возможностью добавления нескольких
   - Интерактивные кнопки для управления процессом
   - Выбор стиля изложения рецепта
   - Возможность отмены операции на любом этапе

3. **Обработка рецептов**:
   - Векторный поиск рецептов по ингредиентам
   - Стилизация текста через LLM
   - Гибкая система стилей с возможностью расширения

4. **Генерация речи**:
   - Использование Silero TTS для синтеза речи
   - Различные голоса и эмоции для разных стилей
   - Сохранение аудиофайлов с уникальными именами

5. **Контейнеризация**:
   - Полная изоляция окружения через Docker
   - Сохранение данных через Docker volumes
   - Автоматический перезапуск при сбоях

## Планируемые улучшения
1. Правильное разбиение на чанки (цепочка Название (обязательно) -> Автор -> Ингредиенты -> Рецепт)
2. Выбор LLM-модели
3. Оплата проприетарной модели звёздами тг
4. Поиск по конкретным магазам на районе 
5. Интеграция с картой
6. Подсчёт суммы приготовления коктейля
7. Поиск только по выбранным ингредиентам
8. Совсем после осуществление поиска по карте за денежку

## Лицензия
Проект распространяется под лицензией MIT. Подробности в файле [LICENSE](LICENSE).