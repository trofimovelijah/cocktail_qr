# ~~Всратое~~ путешествие в мир коктейлей
## Замысел ~~Отель `У погибшего пессимиста`~~
Изначально у меня была идея реализовать возможность поиска по, главным образом, алкогольным коктейлям, исходя из наличия имеющихся у пользователя ин~~ди~~гредиентов. А чтобы он мог сохранять свои находки, можно было реализовать функцию генерации `QR` кода. Однако в ходе предпроектного анализа выяснилось, что подобная возможность не будет востребованной по ряду причин. В связи с этим было решено вместо генерации кодов (к этой идее возможно мы вернёмся впоследствие) реализовать озвучку рецептов. А поскольку имеющиеся возможности синтеза речи не очень хорошо (скорее всего, это реализуемо) воспроизводят интонацию и эмоции, то при прослушивании результата пользователь улыбнётся, покажет/перешлёт товарищу рецепт, и, тем самым, запомнит, что можно сделать из имеющейся под руками алкашки. 

## Основные возможности
### Возможности для приложения в целом
1. Поиск коктейлей своеобразно ведётся по книге `Мастер шейков и «Маргариты». Коктейли для запойных читателей` Тима Федерле
2. Документ разбит на чанки с оптимизацией под выбранную модель
3. Используется многоязычная модель эмбеддингов `paraphrase-multilingual-mpnet-base-v2` 
4. Агент LLM (на базе модели `gpt-3.5-turbo`) осуществляет подбор коктейлей по имеющимся ингредиентам (см. [debug chatgpt.ipynb](/models/debug%20chatgpt.ipynb))
5. Синтез речи с помощью модели `snakers4/silero-models`
6. Ответ синтезируется в речь методом синхронного синтеза. Синхронный подход обоснован необходимостью блокировки выполнения программы до завершения запроса в очереди, что опосредованно влияет на расход дорогостоящих токенов.
7. В ходе отладки приложения было проведено исследование функционирование агента не только с проприетарными моделями от `OpenAI` (`gpt-3.5-turbo` / `gpt-4o-mini`), но и опробовано использование:
   - моднейшем модели `deepseek-llm-7b-chat` (см. тетрадь [debug deepseek.ipynb](/models/debug%20deepseek.ipynb))
   - русифицированной модели `saiga_mistral_7b_gguf:Q8_0` (см. тетрадь [debug saiga mistral.ipynb](/models/debug%20saiga%20mistral.ipynb))
8. Аналогично также был опробован синтез текста с помощью проприетарной модели `SaluteSpeech`, код которой представлен в соответствующем ноутбуке [synthesize_salutspeech.ipynb](/models/synthesize_salutspeech.ipynb)
### Пользовательские возможности
1. Возможность осуществить поиск коктейля по имеющимся ~~в заначке~~ ингредиентам
2. Отображение ответа рецептов коктейлей в выбранном стиле в одном из 4-х стилей
3. Возможность прослушать полученный вариант ответа
4. Стиль ответа (звук, текст) отличается в зависимости от выбора


## Предварительные шаги при развёртывании
1. Перед использованием необходимо в корневой директории создать файл `.env` и поместить в него ключи от `OpenAI` и `huggingFace` в формате:  
    - OPENAI_API_KEY = ключ
    - HUGGINGFACEHUB_API_TOKEN = ключ
    - SBER_API_KEY = ключ_авторизации
    - TELEGRAM_BOT_TOKEN=YOUR_TELEGRAM_BOT_TOKEN_HERE
2. Ежели решили использовать запуск моделей локальных, чтобы денежку не тратить зазря, тогда необходимо предварительно запустить модель. Например, 
   ```bash
   ollama run hf.co/IlyaGusev/saiga_mistral_7b_gguf:Q8_0
   ``` 

## Требования к системе
- Python 3.12+
- Docker и Docker Compose
- Установленные зависимости из requirements.txt:
  - python-telegram-bot
  - python-dotenv
  - langchain и связанные пакеты
  - faiss-cpu
  - sentence-transformers
  - torch и torchaudio
  - silero
  - ollama
- Локально установленная модель Ollama для работы без API

## Порядок развёртывания
1. Клонировать репозиторий:
   ```bash
   git clone <repository_url>
   cd cocktail_qr
   ```

2. Запустить и активировать виртуальное окружение
   ```
   python3 -m venv .venv
   source .venv/bin/activate
   ```
3. Создать файл `.env` в корневой директории с необходимыми ключами:
   ```
   TELEGRAM_BOT_TOKEN=your_telegram_bot_token
   HUGGINGFACEHUB_API_TOKEN=your_huggingface_token
   ```

4. Запустить локальную модель Ollama (если планируется использовать):
   ```bash
   ollama run mistral:instruct
   ```

5. Собрать и запустить контейнер:
   ```bash
   docker-compose up --build
   ```

## Стили отображения рецептов
Доступны следующие стили вывода рецептов:
1. Стиль космического ужаса (Г.Ф. Лавкрафт)
2. Гопническо-быдляцкий жаргон
3. Экспериментальный стиль У. Берроуза
4. Классический стиль (по умолчанию)

## Структура проекта
```
cocktail_qr/
├── Dockerfile
├── docker-compose.yml
├── requirements.txt
├── .env
├── models/
│   ├── __init__.py
│   ├── recipe_finder.py    # Логика поиска рецептов
│   ├── speech_generator.py # Логика генерации речи
│   └── telegram_bot.py     # Основной код бота
├── data/
│   └── faiss_db_epub_mistral/ # Векторное хранилище
├── docs/
│   └── recipes/           # Файлы с рецептами
└── audio/                 # Директория для аудиофайлов
```

## Особенности реализации
1. **Архитектура бота**:
   - Синхронная работа через ConversationHandler
   - Модульная структура с разделением ответственности
   - Сохранение контекста разговора в user_data

2. **Пользовательский интерфейс**:
   - Пошаговый ввод ингредиентов с возможностью добавления нескольких
   - Интерактивные кнопки для управления процессом
   - Выбор стиля изложения рецепта
   - Возможность отмены операции на любом этапе

3. **Обработка рецептов**:
   - Векторный поиск рецептов по ингредиентам
   - Стилизация текста через LLM
   - Гибкая система стилей с возможностью расширения

4. **Генерация речи**:
   - Использование Silero TTS для синтеза речи
   - Различные голоса и эмоции для разных стилей
   - Сохранение аудиофайлов с уникальными именами

5. **Контейнеризация**:
   - Полная изоляция окружения через Docker
   - Сохранение данных через Docker volumes
   - Автоматический перезапуск при сбоях

## Планируемые улучшения
1. Правильное разбиение на чанки (цепочка Название (обязательно) -> Автор -> Ингредиенты -> Рецепт)
2. Выбор LLM-модели
3. Оплата проприетарной модели звёздами тг
4. Поиск по конкретным магазам на районе 
5. Интеграция с картой
6. Подсчёт суммы приготовления коктейля
7. Поиск только по выбранным ингредиентам
8. Совсем после осуществление поиска по карте за денежку

## Лицензия
Проект распространяется под лицензией MIT. Подробности в файле [LICENSE](LICENSE).