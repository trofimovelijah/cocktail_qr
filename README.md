# ~~Всратое~~ путешествие в мир коктейлей
## Замысел ~~Отель `У погибшего пессимиста`~~
Изначально у меня была идея реализовать возможность поиска по, главным образом, алкогольным коктейлям, исходя из наличия имеющихся у пользователя ин~~ди~~гредиентов. А чтобы он мог сохранять свои находки, можно было реализовать функцию генерации `QR` кода. Однако в ходе предпроектного анализа выяснилось, что подобная возможность не будет востребованной по ряду причин. В связи с этим было решено вместо генерации кодов (к этой идее возможно мы вернёмся впоследствие) реализовать озвучку рецептов. А поскольку имеющиеся возможности синтеза речи не очень хорошо (скорее всего, это реализуемо) воспроизводят интонацию и эмоции, то при прослушивании результата пользователь улыбнётся, покажет/перешлёт товарищу рецепт, и, тем самым, запомнит, что можно сделать из имеющейся под руками алкашки. 

## Основные возможности
### Возможности для приложения в целом
1. Поиск коктейлей своеобразно ведётся по книге `Мастер шейков и «Маргариты». Коктейли для запойных читателей` Тима Федерле
2. Документ разбит на чанки с оптимизацией под выбранную модель
3. Используется многоязычная модель эмбеддингов `paraphrase-multilingual-mpnet-base-v2` 
4. Агент LLM (на базе модели `gpt-3.5-turbo`) осуществляет подбор коктейлей по имеющимся ингредиентам (см. [debug chatgpt.ipynb](/models/debug%20chatgpt.ipynb))
5. Синтез речи с помощью модели `snakers4/silero-models`
6. Ответ синтезируется в речь методом синхронного синтеза. Синхронный подход обоснован необходимостью блокировки выполнения программы до завершения запроса в очереди, что опосредованно влияет на расход дорогостоящих токенов.
7. В ходе отладки приложения было проведено исследование функционирование агента не только с проприетарными моделями от `OpenAI` (`gpt-3.5-turbo` / `gpt-4o-mini`), но и опробовано использование:
   - моднейшем модели `deepseek-llm-7b-chat` (см. тетрадь [debug deepseek.ipynb](/models/debug%20deepseek.ipynb))
   - русифицированной модели `saiga_mistral_7b_gguf:Q8_0` (см. тетрадь [debug saiga mistral.ipynb](/models/debug%20saiga%20mistral.ipynb))
8. Аналогично также был опробован синтез текста с помощью проприетарной модели `SaluteSpeech`, код которой представлен в соответствующем ноутбуке [synthesize_salutspeech.ipynb](/models/synthesize_salutspeech.ipynb)
### Пользовательские возможности
1. Возможность осуществить поиск коктейля по имеющимся ~~в заначке~~ ингредиентам
2. Отображение ответа рецептов коктейлей в выбранном стиле в одном из 4-х стилей
3. Возможность прослушать полученный вариант ответа
4. Стиль ответа (звук, текст) отличается в зависимости от выбора


## Предварительные шаги при развёртывании
1. Перед использованием необходимо в корневой директории создать файл utils.key и поместить в него ключи от `OpenAI` и `huggingFace` в формате:  
    - OPENAI_API_KEY = ключ
    - HUGGINGFACEHUB_API_TOKEN = ключ
    - SBER_API_KEY = ключ_авторизации
    - TELEGRAM_BOT_TOKEN=YOUR_TELEGRAM_BOT_TOKEN_HERE
2. Ежели решили использовать запуск моделей локальных, чтобы денежку не тратить зазря, тогда необходимо предварительно запустить модель. Например, 
   ```bash
   ollama run hf.co/IlyaGusev/saiga_mistral_7b_gguf:Q8_0
   ``` 

## Требования к системе
- Python 3.12+
- Установленные зависимости из requirements.txt:
  - langchain и связанные пакеты
  - beautifulsoup4
  - sentence-transformers
  - faiss-cpu
  - unstructured
  - pypandoc
  - transformers
  - requests

## Стили отображения рецептов
Доступны следующие стили вывода рецептов:
1. Стиль космического ужаса (Г.Ф. Лавкрафт)
2. Гопническо-быдляцкий жаргон
3. Экспериментальный стиль У. Берроуза
4. Классический стиль (по умолчанию)

## Структура проекта
- `models/` - основные модели и логика приложения
- `docs/` - файлы с рецептами
- `data/` - векторное хранилище
- `audio/` - хранение аудиозаписей

## Планируемые улучшения
1. Выбор LLM-модели
2. Поиск по конкретным магазам на районе 
3. Интеграция с картой
4. Подсчёт суммы приготовления коктейля
5. Поиск только по выбранным ингредиентам
6. Совсем после осуществление поиска по карте за денежку

## Лицензия
Проект распространяется под лицензией MIT. Подробности в файле [LICENSE](LICENSE).